[
  {
    "objectID": "Lab-7.html",
    "href": "Lab-7.html",
    "title": "DataSkills1",
    "section": "",
    "text": "Truth Table:\n\n\n\n\n\n\n\n\n\n\\(H_0\\) True\n\\(H_0\\) Not True\n\n\n\n\nAccept \\(H_0\\)\nTrue Accept (1-\\(\\alpha\\))\nFalse Accept Type II Error \\(\\beta\\)\n\n\nReject \\(H_0\\)\nFalse Reject Type I error \\(\\alpha\\)\nTrue Reject Power (1-\\(\\beta\\))\n\n\n\n\n\n\\(\\alpha\\) level - This is what you choose a priori (before the experiment). - The probability of rejecting the null hypothesis when the null hypothesis is true - How much of your result is due to chance? - The most common alpha level you will see is .05. - Depending on how strict you want your results to be, you may also see values such as .01 and.001.\nDegrees of Freedom (\\(df\\)) - The number of scores that are free to vary in calculating that statistic Only need to know N to calculate\n\\(df = N - 1\\)\nCritical Values - Cut-off values that define regions where the test statistic is unlikely to lie - Critical values in Table D: Critical Values of Student’s t distribution - Need to know alpha level and df to use the table.",
    "crumbs": [
      "Home",
      "Hypothesis Testing"
    ]
  },
  {
    "objectID": "Lab-7.html#hypothesis-testing",
    "href": "Lab-7.html#hypothesis-testing",
    "title": "DataSkills1",
    "section": "",
    "text": "Truth Table:\n\n\n\n\n\n\n\n\n\n\\(H_0\\) True\n\\(H_0\\) Not True\n\n\n\n\nAccept \\(H_0\\)\nTrue Accept (1-\\(\\alpha\\))\nFalse Accept Type II Error \\(\\beta\\)\n\n\nReject \\(H_0\\)\nFalse Reject Type I error \\(\\alpha\\)\nTrue Reject Power (1-\\(\\beta\\))\n\n\n\n\n\n\\(\\alpha\\) level - This is what you choose a priori (before the experiment). - The probability of rejecting the null hypothesis when the null hypothesis is true - How much of your result is due to chance? - The most common alpha level you will see is .05. - Depending on how strict you want your results to be, you may also see values such as .01 and.001.\nDegrees of Freedom (\\(df\\)) - The number of scores that are free to vary in calculating that statistic Only need to know N to calculate\n\\(df = N - 1\\)\nCritical Values - Cut-off values that define regions where the test statistic is unlikely to lie - Critical values in Table D: Critical Values of Student’s t distribution - Need to know alpha level and df to use the table.",
    "crumbs": [
      "Home",
      "Hypothesis Testing"
    ]
  },
  {
    "objectID": "Lab-7.html#t.test",
    "href": "Lab-7.html#t.test",
    "title": "DataSkills1",
    "section": "T.Test",
    "text": "T.Test\nThe T-test, as you will come to see, is quite similar to the z-test. The main differences are where the information is coming from.\nIf you remember, the z-test takes information from the population such as the mean \\(\\mu\\) and standard deviation \\(\\sigma\\).\nThe t-test takes information from the sample instead.\nYou will notice the formulas are set-up the same way, they just have different numbers.\n\nZ-Test and T-Test Comparison\n\\(Z = \\frac{\\bar{X}-\\mu}{\\sigma_\\bar{X}}\\) and \\(t = \\frac{\\bar{X}-\\mu}{\\sigma_\\bar{X}}\\)\n\nTypes of T-Tests\nThere are three types of T-Tests, but we will only be learning one for today.\n\nT-Test for single samples\n\n\\[t = \\frac{\\bar{X}-\\mu}{\\sigma_\\bar{X}}\\]\n\nT-Test for paired samples\n\n\\[t = \\frac{\\bar{D}}{\\sigma_\\bar{D}}\\] - T-Test for independent samples\n\\[t = \\frac{\\bar{X}_1 - \\bar{X}_2}{\\sqrt{\\frac{S^2_1}{N_1}+\\frac{S^2_2}{N_2}}}\\]\n\nT-Test Example (R-Calculation)\nLet us start off with a sample of 20 scores:\n\nset.seed(123)\nReaction_Time = round(rnorm(20,550,10.5),digits=2)\nnull_mu = 670\nt.test(Reaction_Time,mu=null_mu)\n\n\n    One Sample t-test\n\ndata:  Reaction_Time\nt = -51.897, df = 19, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 670\n95 percent confidence interval:\n 546.7078 556.2672\nsample estimates:\nmean of x \n 551.4875 \n\n\n\nWriting our results\nAs we discussed in the previous lecture, we will need to make sure to report our findings in proper statistical formats.\nSpecifically, when we report the results of a t-test it should look like this:\n\\[t = -51.897, p &lt;.001\\]\n\n\n\nT-Test Example (Hand-Calculation)\n\\[t = \\frac{\\bar{X}-\\mu}{\\sigma_\\bar{X}}\\] Let us imagine we have 10 numbers:\n\n{111.66,117.50,104.82,146.03,134.50,106.52,115.17,114.40,129.36,119.00}\n\nThese numbers have a standard deviation of 12.99.\nFirst, we will need to take the mean:\n\\[\\frac{111.66+117.50+104.82+146.03+134.50+106.52+115.17+114.40+129.36+119.00}{10} = 119.896\\]\nWe want to see if this mean is different from the population mean (\\(\\mu\\)), 126.42.\nWe will also need to solve for the standard error of the mean (\\(s_\\bar{X}\\))\nRemember that \\(s_\\bar{X} = \\frac{s}{\\sqrt{n}}\\)\n\\(s_\\bar{X} = \\frac{12.99}{\\sqrt{10}} = 4.107\\)\nOur new equation should look something like this:\n\\(t = \\frac{119.896-126.42}{4.107} = -1.588\\)\n\\(t = -1.588\\)\nYou’ll notice that when we did the t-test in R we were given a p-value. When you calculate the value by hand, there is no such luck! So, you will have to check for a critical value to see if the value you’ve calculated is past the rejection zone.\nLet’s make sure this works in R as well:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Home",
      "Hypothesis Testing"
    ]
  },
  {
    "objectID": "Lab-7.html#power",
    "href": "Lab-7.html#power",
    "title": "DataSkills1",
    "section": "Power",
    "text": "Power\nWhen we talk about power in the context of an experiment, we are referring to the probability of detecting an effect if the effect exists in nature. Power is an important part of experimental design. One of its many uses is in the realm of grant proposals. Let’s imagine you want to run an experiment and you would also like a grant so you can fund the study. When you propose the study, the board that will be reviewing your claim will want to know if it is likely to work. If you can show them that your experiment has high power, you will need fewer participants to find the effect (if it exists), and will cost less money!\nThere are several ways to compute power, however, we will focus on the computer assisted method, using a program called G-Power. You will not be required to know how to use the program intricately, rather, you will just have to know how to interpret the output of the program as well as input one or two parameters.",
    "crumbs": [
      "Home",
      "Hypothesis Testing"
    ]
  },
  {
    "objectID": "Review-Sheet.html",
    "href": "Review-Sheet.html",
    "title": "DataSkills1",
    "section": "",
    "text": "Exam 1 R-Review Sheet\n\nFunctions and Arguments\nHere are some important functions and arguments to know:\nplot() - This is the function to graphically visualize your data. Within this function can be several arguments.\n\nx,y:The independent and dependent variable you are interested in\nmain =,xlab =, ylab =, sub =: Title, x-axis lable, y-axis label, and caption.\nxlim =,ylim =: These set parameters for the graph that will be drawn.\ncol = : Designates a desired color for the lines, and points that will be drawn.\npch =: Point character, assigns shape for points drawn.\npoints(): Plot additional points on an existing graph with pre-defined graphical parameters\n\n-cor() - This function will return the correlation, or r, of an entire dataframe, or of specified variables.\n-hist() - This function will create a histogram of a given variable, displaying its frequencies.\n\nbreaks = - This argument allows you to specify a bin width of your choice.\nlm() - This function allows you to create a linear model from which you can predict a variable, from another.\n\nthe ~ is used to delineate between the predicting variable and the predictor variable.\n\nFor example: lm(x~y) is different than lm(y~x).\n\nWhen using lm(), it is common to name the model something that makes sense + .mod..\n\n\n-summary() - This can be used on entire datasets to return the minimum, maximum, and median values.\n\nThis can also be used to expand a linear model to give you values such as the coefficient of correlation, slope and intercept.\n\n\n\nSyntax\nWhen using R-Studio, it is important that the math you do in the console follows the same rules as the math you would do on a calculator or a piece of paper.\nFor example:\nI have a dataset with a mean of 10, and a standard deviation of 7. What is the probability of having a score of 18?\nWe know the formula for this is the Z-Score formula: \\[z = \\frac{x - M}{\\sigma}\\] Depending on how you enter this data into R, you will get two different answers:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n() are very important to R, and your answers will either be incorrect or will not be ouput corectly if the () are misplaced/misused. Depending on how difficult you want to make your calculations, keeping track of your () placement is very important.\nThe below equation will not render the correct answer:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nNot too bad, we were only off by one hundred and fourteen thousand six hundred nintey-four.\n\nMath Operators\n() matter, quite a lot. Additionally, here are the math operators you can use:\n+\n-\n*\n/\n^\nsqrt()",
    "crumbs": [
      "Home",
      "Exam 1 R-Review Sheet"
    ]
  },
  {
    "objectID": "Lab-11.html",
    "href": "Lab-11.html",
    "title": "DataSkills1",
    "section": "",
    "text": "Recall the way that the ANOVA is formatted:\n\nonefact &lt;- \n  data.frame(groups = rep(c(\"Control\",\"Treatment 1\", \"Treatment 2\"), each = 20),\n             score = c(rnorm(20,10),rnorm(20,15),rnorm(20,22)))\n\nhead(onefact)\n\n   groups     score\n1 Control 10.053947\n2 Control 10.705475\n3 Control 10.503910\n4 Control  8.875389\n5 Control  8.802727\n6 Control 10.602503\n\n\nWe have three independent variables, or conditions, control, treatment 1 and treatment 2. We have one dependent variable, some idea of “score” or our dependent variabe.\nThe ANOVA is analyzed through the use of the aov function. Remember to save the analysis as a model so you can use it later if you need to do any post-hoc tests/unplanned comparisons.\n\nonefact.mod &lt;- aov(score~groups, data=onefact)\n\nsummary(onefact.mod)\n\n            Df Sum Sq Mean Sq F value Pr(&gt;F)    \ngroups       2 1552.4   776.2   719.7 &lt;2e-16 ***\nResiduals   57   61.5     1.1                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThis produces a sum of squares and mean squares for the between subjects factor, groups. It also produces a sum of squares and mean squares for the within subjects factor, also called the residuals, or the error.\nFrom this we get one F-value.\nThe current design will not help us too much so we need to move on to another design, the two factor between subjects ANOVA.\nThe set-up is mostly the same:\n\ntwofact.df &lt;- \n   data.frame(Gender=c(rep(\"Male\", 30), rep(\"Female\",30)),\n              Diet= c(rep(c(\"Diet 1\", \"Diet 2\"), 30)),\n              Count=c(rnorm(30,28,2),rnorm(30,35,2)))\n twofact.df\n\n   Gender   Diet    Count\n1    Male Diet 1 29.28565\n2    Male Diet 2 27.77193\n3    Male Diet 1 28.77947\n4    Male Diet 2 27.13819\n5    Male Diet 1 27.68155\n6    Male Diet 2 32.14686\n7    Male Diet 1 26.74604\n8    Male Diet 2 26.48680\n9    Male Diet 1 27.70064\n10   Male Diet 2 24.20712\n11   Male Diet 1 28.64474\n12   Male Diet 2 27.62731\n13   Male Diet 1 29.02422\n14   Male Diet 2 26.43496\n15   Male Diet 1 26.09912\n16   Male Diet 2 25.31223\n17   Male Diet 1 27.34079\n18   Male Diet 2 28.09060\n19   Male Diet 1 29.34636\n20   Male Diet 2 31.89925\n21   Male Diet 1 27.50672\n22   Male Diet 2 24.67519\n23   Male Diet 1 28.41077\n24   Male Diet 2 26.41232\n25   Male Diet 1 30.45810\n26   Male Diet 2 27.96039\n27   Male Diet 1 31.47558\n28   Male Diet 2 27.71842\n29   Male Diet 1 29.11803\n30   Male Diet 2 25.88075\n31 Female Diet 1 36.56940\n32 Female Diet 2 37.10854\n33 Female Diet 1 39.75562\n34 Female Diet 2 33.67428\n35 Female Diet 1 36.03668\n36 Female Diet 2 34.20005\n37 Female Diet 1 34.42411\n38 Female Diet 2 31.63277\n39 Female Diet 1 36.83795\n40 Female Diet 2 35.80431\n41 Female Diet 1 36.30694\n42 Female Diet 2 30.80953\n43 Female Diet 1 34.73127\n44 Female Diet 2 36.05144\n45 Female Diet 1 33.65283\n46 Female Diet 2 33.32218\n47 Female Diet 1 36.15832\n48 Female Diet 2 33.17340\n49 Female Diet 1 34.93337\n50 Female Diet 2 32.42822\n51 Female Diet 1 33.02687\n52 Female Diet 2 34.26264\n53 Female Diet 1 37.21966\n54 Female Diet 2 38.13742\n55 Female Diet 1 35.71552\n56 Female Diet 2 37.01317\n57 Female Diet 1 38.69807\n58 Female Diet 2 36.73326\n59 Female Diet 1 37.52918\n60 Female Diet 2 37.74209\n\n\nWe can see that there are two levels of the independent variable (gender) and two levels of the independent variable (Diet) and one dependent variable, count.\nFrom this we will generate four sums of squares and four mean squares. - Sum of Squares for Factor A - Sum of Squares for Factor B - - Sum of Squares for the interaction between A and B - Sum of Squares within, or Error, or residual.\nAnalyzing the data just uses one more term:\n\ntwofact.mod&lt;-aov(Count~Gender*Diet,data = twofact.df)\nsummary(twofact.mod)\n\n            Df Sum Sq Mean Sq F value Pr(&gt;F)    \nGender       1  853.6   853.6 218.647 &lt;2e-16 ***\nDiet         1   23.3    23.3   5.958 0.0178 *  \nGender:Diet  1    0.0     0.0   0.012 0.9147    \nResiduals   56  218.6     3.9                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWhat do these results look like?\nIn order to plot these relationships we can use interaction.plot.\n\ninteraction.plot(twofact.df$Gender,twofact.df$Diet, twofact.df$Count)\n\n\n\n\n\n\n\n\n\ndf &lt;- \n  data.frame(iv1 = rep(c(\"Level 1\",\"Level 2\"),each=2,20),\n             iv2 = rep(c(\"Level 1\",\"Level 2\"),each=1,40),\n             scored = rnorm(80,c(15,20,30,40)))\n\n\nlength(df$iv1)\n\n[1] 80\n\nlength(df$iv2)\n\n[1] 80\n\nlength(df$scored)\n\n[1] 80\n\nsummary(aov(scored~iv1*iv2,data = df))\n\n            Df Sum Sq Mean Sq F value   Pr(&gt;F)    \niv1          1   5989    5989 4487.65  &lt; 2e-16 ***\niv2          1   1157    1157  866.93  &lt; 2e-16 ***\niv1:iv2      1    129     129   96.52 3.57e-15 ***\nResiduals   76    101       1                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ninteraction.plot(df$iv1,df$iv2,df$scored)",
    "crumbs": [
      "Home",
      "Two Factor Between Subject ANOVA"
    ]
  },
  {
    "objectID": "Lab-11.html#two-factor-between-subject-anova",
    "href": "Lab-11.html#two-factor-between-subject-anova",
    "title": "DataSkills1",
    "section": "",
    "text": "Recall the way that the ANOVA is formatted:\n\nonefact &lt;- \n  data.frame(groups = rep(c(\"Control\",\"Treatment 1\", \"Treatment 2\"), each = 20),\n             score = c(rnorm(20,10),rnorm(20,15),rnorm(20,22)))\n\nhead(onefact)\n\n   groups     score\n1 Control 10.053947\n2 Control 10.705475\n3 Control 10.503910\n4 Control  8.875389\n5 Control  8.802727\n6 Control 10.602503\n\n\nWe have three independent variables, or conditions, control, treatment 1 and treatment 2. We have one dependent variable, some idea of “score” or our dependent variabe.\nThe ANOVA is analyzed through the use of the aov function. Remember to save the analysis as a model so you can use it later if you need to do any post-hoc tests/unplanned comparisons.\n\nonefact.mod &lt;- aov(score~groups, data=onefact)\n\nsummary(onefact.mod)\n\n            Df Sum Sq Mean Sq F value Pr(&gt;F)    \ngroups       2 1552.4   776.2   719.7 &lt;2e-16 ***\nResiduals   57   61.5     1.1                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThis produces a sum of squares and mean squares for the between subjects factor, groups. It also produces a sum of squares and mean squares for the within subjects factor, also called the residuals, or the error.\nFrom this we get one F-value.\nThe current design will not help us too much so we need to move on to another design, the two factor between subjects ANOVA.\nThe set-up is mostly the same:\n\ntwofact.df &lt;- \n   data.frame(Gender=c(rep(\"Male\", 30), rep(\"Female\",30)),\n              Diet= c(rep(c(\"Diet 1\", \"Diet 2\"), 30)),\n              Count=c(rnorm(30,28,2),rnorm(30,35,2)))\n twofact.df\n\n   Gender   Diet    Count\n1    Male Diet 1 29.28565\n2    Male Diet 2 27.77193\n3    Male Diet 1 28.77947\n4    Male Diet 2 27.13819\n5    Male Diet 1 27.68155\n6    Male Diet 2 32.14686\n7    Male Diet 1 26.74604\n8    Male Diet 2 26.48680\n9    Male Diet 1 27.70064\n10   Male Diet 2 24.20712\n11   Male Diet 1 28.64474\n12   Male Diet 2 27.62731\n13   Male Diet 1 29.02422\n14   Male Diet 2 26.43496\n15   Male Diet 1 26.09912\n16   Male Diet 2 25.31223\n17   Male Diet 1 27.34079\n18   Male Diet 2 28.09060\n19   Male Diet 1 29.34636\n20   Male Diet 2 31.89925\n21   Male Diet 1 27.50672\n22   Male Diet 2 24.67519\n23   Male Diet 1 28.41077\n24   Male Diet 2 26.41232\n25   Male Diet 1 30.45810\n26   Male Diet 2 27.96039\n27   Male Diet 1 31.47558\n28   Male Diet 2 27.71842\n29   Male Diet 1 29.11803\n30   Male Diet 2 25.88075\n31 Female Diet 1 36.56940\n32 Female Diet 2 37.10854\n33 Female Diet 1 39.75562\n34 Female Diet 2 33.67428\n35 Female Diet 1 36.03668\n36 Female Diet 2 34.20005\n37 Female Diet 1 34.42411\n38 Female Diet 2 31.63277\n39 Female Diet 1 36.83795\n40 Female Diet 2 35.80431\n41 Female Diet 1 36.30694\n42 Female Diet 2 30.80953\n43 Female Diet 1 34.73127\n44 Female Diet 2 36.05144\n45 Female Diet 1 33.65283\n46 Female Diet 2 33.32218\n47 Female Diet 1 36.15832\n48 Female Diet 2 33.17340\n49 Female Diet 1 34.93337\n50 Female Diet 2 32.42822\n51 Female Diet 1 33.02687\n52 Female Diet 2 34.26264\n53 Female Diet 1 37.21966\n54 Female Diet 2 38.13742\n55 Female Diet 1 35.71552\n56 Female Diet 2 37.01317\n57 Female Diet 1 38.69807\n58 Female Diet 2 36.73326\n59 Female Diet 1 37.52918\n60 Female Diet 2 37.74209\n\n\nWe can see that there are two levels of the independent variable (gender) and two levels of the independent variable (Diet) and one dependent variable, count.\nFrom this we will generate four sums of squares and four mean squares. - Sum of Squares for Factor A - Sum of Squares for Factor B - - Sum of Squares for the interaction between A and B - Sum of Squares within, or Error, or residual.\nAnalyzing the data just uses one more term:\n\ntwofact.mod&lt;-aov(Count~Gender*Diet,data = twofact.df)\nsummary(twofact.mod)\n\n            Df Sum Sq Mean Sq F value Pr(&gt;F)    \nGender       1  853.6   853.6 218.647 &lt;2e-16 ***\nDiet         1   23.3    23.3   5.958 0.0178 *  \nGender:Diet  1    0.0     0.0   0.012 0.9147    \nResiduals   56  218.6     3.9                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWhat do these results look like?\nIn order to plot these relationships we can use interaction.plot.\n\ninteraction.plot(twofact.df$Gender,twofact.df$Diet, twofact.df$Count)\n\n\n\n\n\n\n\n\n\ndf &lt;- \n  data.frame(iv1 = rep(c(\"Level 1\",\"Level 2\"),each=2,20),\n             iv2 = rep(c(\"Level 1\",\"Level 2\"),each=1,40),\n             scored = rnorm(80,c(15,20,30,40)))\n\n\nlength(df$iv1)\n\n[1] 80\n\nlength(df$iv2)\n\n[1] 80\n\nlength(df$scored)\n\n[1] 80\n\nsummary(aov(scored~iv1*iv2,data = df))\n\n            Df Sum Sq Mean Sq F value   Pr(&gt;F)    \niv1          1   5989    5989 4487.65  &lt; 2e-16 ***\niv2          1   1157    1157  866.93  &lt; 2e-16 ***\niv1:iv2      1    129     129   96.52 3.57e-15 ***\nResiduals   76    101       1                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ninteraction.plot(df$iv1,df$iv2,df$scored)",
    "crumbs": [
      "Home",
      "Two Factor Between Subject ANOVA"
    ]
  },
  {
    "objectID": "Lab-11.html#two-factor-within-subjects-anova",
    "href": "Lab-11.html#two-factor-within-subjects-anova",
    "title": "DataSkills1",
    "section": "Two Factor Within Subjects ANOVA",
    "text": "Two Factor Within Subjects ANOVA\nIn a Two Factor Between Subjects ANOVA, a particular participant is only ever in one condition or group or treatment level.\nIn a Two Factor Within Subjects ANOVA, a particular participant is in each condition or group or treatment level.\nSetting this data up uses the same principles as we have learned before.\nThe one major difference in the set-up of the data is that there is now a variable of the subject itself.\nWhen we had a between subjects design, each participant was unique, with a within deisgn, each participant experiences every aspect of the experiment so it is reasonable that they may have an effect on the experiment itself.\nHere is a sample dataset:\n\nset.seed(1234)\n\nwithin_anova &lt;- \n  data.frame(subject=rep(1:10,4),\n             groups=rep(c(\"pre\",\"post\",\"post 1\", \"post 2\"),each = 10),\n             score=rnorm(40,c(20,30,40,70)))\n\nhead(within_anova)\n\n  subject groups    score\n1       1    pre 18.79293\n2       2    pre 30.27743\n3       3    pre 41.08444\n4       4    pre 67.65430\n5       5    pre 20.42912\n6       6    pre 30.50606\n\n\nIt would be helpful if we could see the means of each group, and plot those means.\nFor this, we will use a new function called tapply. This applies a specified function to whatever variables you provide in the arguments.\nTo get the means:\n\nwithin_means &lt;- \n  tapply(within_anova$score,within_anova$groups,mean)\n\nwithin_means\n\n    post   post 1   post 2      pre \n42.88183 36.61205 42.23381 36.61684 \n\n\nTo get the standard deviations:\n\nwithin_sd &lt;- \n  tapply(within_anova$score,within_anova$groups,sd)\n\nwithin_sd\n\n    post   post 1   post 2      pre \n20.47817 18.96593 20.24584 18.49391 \n\n\nFor now, we will only use tapply in order to get the means.\nHere is how we will plot the means:\n\nplot(within_means, pch=19,\n      xlab = \"Treatments\",\n      ylab = \"Survey Score\",\n      main = \"Means of Survey Score by Treatment\")\n\n\n\n\n\n\n\n\nPerforming the ANOVA requires two new terms: Error and the Subject factor.\nThe model that the ANOVA should resemble looks like this:\naov(DV~IV+Error(Subjects))\nFrom here it is important to note that your IV *must* be a factor.\nWith this in mind, you should run the function levels(Grouping Variable) or factor(Grouping Variable.)\nIf the first function returns NULL, use the second function.\nPutting all of this together gives us the following:\n\nwithin_anova.mod &lt;- aov(score~groups+Error(subject),data = within_anova)\nsummary(within_anova.mod)\n\n\nError: subject\n          Df Sum Sq Mean Sq F value Pr(&gt;F)\nResiduals  1  113.9   113.9               \n\nError: Within\n          Df Sum Sq Mean Sq F value Pr(&gt;F)\ngroups     3    355   118.4   0.303  0.823\nResiduals 35  13665   390.4               \n\n\nWhen reporting these findings, you will ignore the subject variable and report the F-value for the grouping variable.\nThis particular finding should be reported as follows:\n\\(F(3,35) = .303, p &gt;.05\\)\n\nThe results of a one-factor within subjects ANOVA revealed that there does not appear to be any effect of treatment on survey score.",
    "crumbs": [
      "Home",
      "Two Factor Between Subject ANOVA"
    ]
  },
  {
    "objectID": "Lab-11.html#effect-sizes",
    "href": "Lab-11.html#effect-sizes",
    "title": "DataSkills1",
    "section": "Effect Sizes",
    "text": "Effect Sizes\nMost times you will want to report effect sizes for your experiment. Effect sizes help to tell you how much of your effect is due to your manipulation.\nIn this example, there does not appear to be an effect at all, but we will compute an effect size anyways.\nWe will be using the \\(\\omega^2\\) effect size estimate.\nThe formula is as follows:\n\\[\\omega^2 = \\frac{SS_B-(k-1)(MS_W)}{SS_T-MS_W}\\]\nor\n\\[\\omega^2 = \\frac{SS_{Effect}-(k-1)(MS_{Within})}{SS_{Total}-MS_{Within}}\\]\nThere is no R function that reports \\(\\omega^2\\), so we will do this by hand.\n\\(\\omega^2 = \\frac{355-(4-1)(390.4)}{14020-390.4}\\)\n\\(\\omega^2 = -.059\\)\nThis effect size is negative because our effect was not significant, but it is still important for you to see how to get these numbers!",
    "crumbs": [
      "Home",
      "Two Factor Between Subject ANOVA"
    ]
  },
  {
    "objectID": "Lab-12.html",
    "href": "Lab-12.html",
    "title": "DataSkills1",
    "section": "",
    "text": "In this class we have learned the following, parametric tests, that is, tests that work when we have data on an interval or ratio scale:\n\nZ-test\nT-Test\n\nSingle Sample\nDependent Samples\nIndependent Samples\n\nOne Factor ANOVA\n\nBetween\nWithin\n\nTwo Factor ANOVA\n\nBetween\n\n\nThese tests all share something in common in that our results are estimates of aparameter, and they all are derived from a distribution. Additionally, these tests make assumptions about where the data comes from, i.e. normally distributed, equal variances etc.\nWhat happens when our data does not meet these criteria? Do we throw our data out? No!\nWe use non-parametric tests. These tests are distribution-free. Think of these tests\nas another version of what we have already learned.\n\n\n\nInstead of a Paired t-test, we can use a Wilcoxin Signed Ranks test.\nInstead of a Pearson correlation, we can use a Spearman correlation.\nInstead of an Independent T-Test, we can use a Mann-Whitney U test.\nInstead of a One Way ANOVA, we can use a Kruskal Wallis Test instead.\nInstead of a Two Way ANOVA, we can use a Friedman Test.\n\n\n\n\nOne of the non-parametric tests that does not have a direct equivalence is the chi square test. For this lab you will only need to know about two.\nThe Chi Square Goodness of Fit test, and the Chi-Square test for independence.\n\n\nThe Goodness of fit test compares whether observed distribution matches an expected distribution.\n\nImagine that we go out into a wealthy neighborhood and we count 81 Teslas, 50 Ferrari’s, and 27 Saturn’s.\n\nAre these car makes equally common in this neighborhood?\nIf these car makes were equally common in wealthy neighborhoods, the proportion of them would be \\(\\frac{1}{3}\\) each.\nHowever, in this wealthy part of town, the breakdown should be:\n\n\\(\\frac{1}{2} = Tesla\\)\n\\(\\frac{1}{3} = Ferrari\\)\n\\(\\frac{1}{6} = Saturn\\)\n\nIs there a significant difference between the observed frequencies and the expected frequencies?\nIn R, we can use the chisq.test(x,p) function where x = a numeric vector, and p represents probabilities of the same length as `x.\nTo see if the car makes are equally common in the neighborhood we would create our data:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nThe proper way to report this would be as follows:\n\\(\\chi^2(2) = 27.886, p &lt;.01\\)\nNow we ask whether or not there is a difference in what we observed and what we expected.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nAre these observed frequencies significantly different from the expected frequencies?\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\\(\\chi^2(2) p &gt; .05\\)\n\nThere is not a significant different in our observed frequencies and the expected frequencies.\n\n\n\n\n\nSimilarly, we can use a Chi Square test to see if there is a significant difference in two different groups. For this we will need to make a table.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\\(\\chi^2(4) = 16.025, p &lt;.01\\)\n\n\n\n\nSpearman Rho is another way of obtaining a correlation. Let us make a dataframe, plot the variables and calculate a correlation value:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nrs(12) =.81, p &lt; .05\n\n\n\n\n\nWe can use this test when comparing two dependent groups:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\\(U_{obt} = 77, NS\\)\n\n\n\n\nWe can use the Wilcoxin Signed Ranks Test when comparing two dependent groups:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\\(V(12) = 15.5, p &gt;.05\\)\n\n\n\n\nWe can use the Kruskal Wallis Test when we want to test several independent variables.\nImagine we have the following data:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThe problem with this data is that we cannot directly do an analysis because the data type is character. We can recode this like such:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\\(H(4) = 10.677, p = .013\\)\n\n\n\n\nWe can use a Friedman Test when we want to compare the effect of two or more independent variables on a dependent variable like such:\nRemember: This test is designed to replicate the two-way ANOVA, just with different data types, because of this your data needs to look similar.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\\(fr_{obt} (3), = .67,,N.S\\)",
    "crumbs": [
      "Home",
      "Non-Parametric Tests"
    ]
  },
  {
    "objectID": "Lab-12.html#non-parametric-tests",
    "href": "Lab-12.html#non-parametric-tests",
    "title": "DataSkills1",
    "section": "",
    "text": "In this class we have learned the following, parametric tests, that is, tests that work when we have data on an interval or ratio scale:\n\nZ-test\nT-Test\n\nSingle Sample\nDependent Samples\nIndependent Samples\n\nOne Factor ANOVA\n\nBetween\nWithin\n\nTwo Factor ANOVA\n\nBetween\n\n\nThese tests all share something in common in that our results are estimates of aparameter, and they all are derived from a distribution. Additionally, these tests make assumptions about where the data comes from, i.e. normally distributed, equal variances etc.\nWhat happens when our data does not meet these criteria? Do we throw our data out? No!\nWe use non-parametric tests. These tests are distribution-free. Think of these tests\nas another version of what we have already learned.\n\n\n\nInstead of a Paired t-test, we can use a Wilcoxin Signed Ranks test.\nInstead of a Pearson correlation, we can use a Spearman correlation.\nInstead of an Independent T-Test, we can use a Mann-Whitney U test.\nInstead of a One Way ANOVA, we can use a Kruskal Wallis Test instead.\nInstead of a Two Way ANOVA, we can use a Friedman Test.\n\n\n\n\nOne of the non-parametric tests that does not have a direct equivalence is the chi square test. For this lab you will only need to know about two.\nThe Chi Square Goodness of Fit test, and the Chi-Square test for independence.\n\n\nThe Goodness of fit test compares whether observed distribution matches an expected distribution.\n\nImagine that we go out into a wealthy neighborhood and we count 81 Teslas, 50 Ferrari’s, and 27 Saturn’s.\n\nAre these car makes equally common in this neighborhood?\nIf these car makes were equally common in wealthy neighborhoods, the proportion of them would be \\(\\frac{1}{3}\\) each.\nHowever, in this wealthy part of town, the breakdown should be:\n\n\\(\\frac{1}{2} = Tesla\\)\n\\(\\frac{1}{3} = Ferrari\\)\n\\(\\frac{1}{6} = Saturn\\)\n\nIs there a significant difference between the observed frequencies and the expected frequencies?\nIn R, we can use the chisq.test(x,p) function where x = a numeric vector, and p represents probabilities of the same length as `x.\nTo see if the car makes are equally common in the neighborhood we would create our data:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nThe proper way to report this would be as follows:\n\\(\\chi^2(2) = 27.886, p &lt;.01\\)\nNow we ask whether or not there is a difference in what we observed and what we expected.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nAre these observed frequencies significantly different from the expected frequencies?\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\\(\\chi^2(2) p &gt; .05\\)\n\nThere is not a significant different in our observed frequencies and the expected frequencies.\n\n\n\n\n\nSimilarly, we can use a Chi Square test to see if there is a significant difference in two different groups. For this we will need to make a table.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\\(\\chi^2(4) = 16.025, p &lt;.01\\)\n\n\n\n\nSpearman Rho is another way of obtaining a correlation. Let us make a dataframe, plot the variables and calculate a correlation value:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nrs(12) =.81, p &lt; .05\n\n\n\n\n\nWe can use this test when comparing two dependent groups:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\\(U_{obt} = 77, NS\\)\n\n\n\n\nWe can use the Wilcoxin Signed Ranks Test when comparing two dependent groups:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\\(V(12) = 15.5, p &gt;.05\\)\n\n\n\n\nWe can use the Kruskal Wallis Test when we want to test several independent variables.\nImagine we have the following data:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThe problem with this data is that we cannot directly do an analysis because the data type is character. We can recode this like such:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\\(H(4) = 10.677, p = .013\\)\n\n\n\n\nWe can use a Friedman Test when we want to compare the effect of two or more independent variables on a dependent variable like such:\nRemember: This test is designed to replicate the two-way ANOVA, just with different data types, because of this your data needs to look similar.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\\(fr_{obt} (3), = .67,,N.S\\)",
    "crumbs": [
      "Home",
      "Non-Parametric Tests"
    ]
  },
  {
    "objectID": "Lab-3.html",
    "href": "Lab-3.html",
    "title": "DataSkills1",
    "section": "",
    "text": "Correlation refers to the strength of the relationship between two different variables.\nCorrelation is often represented by the letter r.\nThe equation for correlation(r) looks a little intimidating but if it is broken down into steps, it is much more manageable.\n\\(r = \\frac{n(\\sum(xy)-(\\sum x)(\\sum(y))}{\\sqrt{n \\sum x ^2-(\\sum x)^2][n \\sum y ^2-(\\sum y)^2]}}\\)\nLet’s take a closer look at the denominator first:\n\n\\(n(\\sum(xy)-(\\sum x)(\\sum(y))\\)\n\nThe first thing we should do is have a dataset to work with:\nx = 5, 5, 4, 4, 5, 5, 4, 5, 3, 5, 6, 6, 5, 6, 6 y = 13, 12, 13, 14, 13, 12, 11, 12, 11, 12, 13, 12, 12, 13, 13\nEach dataset has 15 data points. When you work with larger datasets you may want to avoid having to count each number so r has a built in function called length() which will return the number of items in your variable. We know our first term is 15 so we will add that to the formula.\n\n\\(r = \\frac{15(\\sum(xy)-(\\sum x)(\\sum(y))}{\\sqrt{15 \\sum x ^2-(\\sum x)^2][15 \\sum y ^2-(\\sum y)^2]}}\\)\n\nThe next part is asking us to compute the sum of the values of x multiplied by the values of y and then add that to the formula.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\\(r = \\frac{15(921)-(\\sum x)(\\sum(y))}{\\sqrt{15 \\sum x ^2-(\\sum x)^2][15 \\sum y ^2-(\\sum y)^2]}}\\)\n\nNext we need to subtract this amount from the result from the product of the sum of all of the values of x and the sum of all the values of y.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\\(r = \\frac{15(921-(74)(186)}{\\sqrt{15 \\sum x ^2-(\\sum x)^2][15 \\sum y ^2-(\\sum y)^2]}}\\)\n\nLet’s just take care of the numerator for now.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\\(r = \\frac{51}{\\sqrt{15 \\sum x ^2-(\\sum x)^2][15 \\sum y ^2-(\\sum y)^2]}}\\)\n\nAlright, now let us look at the denominator.\n\\({\\sqrt{15 \\sum x ^2-(\\sum x)^2][15 \\sum y ^2-(\\sum y)^2]}}\\)\nYou should notice that the denominator is sort of a mirror image, the first part handles x and the second part handles y.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\\(r = {\\sqrt{15(376)-(\\sum x)^2][15(2316))-(\\sum y)^2]}}\\)\n\nAgain, the same thing is being done to x and y. We are going to sum the values in x and then square them, and do the same to the values in y.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\\({\\sqrt{15(376)-5,476][15(2316))-34,596]}}\\)\n\nNow we can clean up the denominator:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\\(r = \\frac{51}{153.675}\\)\n\nNow divide\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\\(r = 0.33\\)\n\nBefore we start discussing what that means, let us see the other way of calculating r (there are many)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThat seems a lot easier than the eight steps we went through!\nThe important thing to remember is that while R can do things for you very fast, it is important that you know why you are doing them in the first place!\nSo we found that for our data, the r was equal to r. This is a relatively weak correlation. In psychology you will likely never see correlations that are above .9. This obtained r of r cor(x,y) would indicate some positive correlation. In order to obtain \\(R^2\\)we simply square the obtained r and get r corxy^2\nHere is what a plot of the data looks like:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nIt would be hard to guess a correlation by just looking at this data. There are only 15 points, but we can tell they are not all in the same space, nor are they all randomly dispersed. So if we had to take a guess, we could assume that a slight correlation could be present.\nLet us take a look at a data set with some meaning and more data points.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Home",
      "Correlation"
    ]
  },
  {
    "objectID": "Lab-3.html#linear-regression",
    "href": "Lab-3.html#linear-regression",
    "title": "DataSkills1",
    "section": "Linear Regression",
    "text": "Linear Regression\nLinear regression refers to an equation of the “best fitting line” that shows where a line could be placed taht would best explain the relationship, if any, or your data.\nThe equation is as follows:\n\\(\\hat{Y_x} = a_x + b_yx\\)\nWhere \\(\\hat{Y}\\) equals the predicted value of Y given X.\nIn order to find b:\n\\(b = \\frac{n\\sum XY -\\sum X\\sum Y }{n\\sum X^2-\\sum (X)^2}\\) or \\(b = \\frac{\\sum XY }{\\sum X^2}\\)\nIn order to fid a:\n\\(a = \\mathrel{\\bar{Y}}-b\\mathrel{\\bar{X}}\\)\nLet us work with a sample set of data:\nx = 20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95,100\ny = 10.93,11.78,10.97,11.27,11.37,10.31,12.84,12.15,10.86,13.25,12.43,11.70,12.90 12.8,12.82,12.69,12.55\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\\(n\\sum XY -\\sum X\\sum Y\\)\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\\(b = \\frac{243.25}{n\\sum X^2-\\sum (X)^2}\\)\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\\(b = \\frac{243.25}{10,200}\\)\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\\(a = \\mathrel{\\bar{Y}}-b\\mathrel{\\bar{X}}\\)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\\(\\hat{Y} = 10.546 + .0238x\\)\n\\(\\frac{\\sum(X-\\mathrel{\\bar{X}}^2)\\sum(Y-\\mathrel{\\bar{Y}}^2)}{\\sum(X-\\mathrel{\\bar{X}})^2}\\)\nor\n\\(\\frac{SSxy}{SSx}\\)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\\(\\frac{243.25}{10,200}\\)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\\(\\hat{Y} = 10.546 + .0238x\\)\nAs with correlation, there is an ‘easier’ way to find the equation for the best fitting line.\nNow, let us use the lm() function to create the prediction equation. What you will notice is the use of &lt;-, which is another way of assignment. We will also name the equation prediction xy.mod. which stands for model.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nFrom the above output you should note a few things: the number across from the (Intercept) will be your value for a. The number across from x will be your value for b. This summary() will also give you other statistics such as the R-squared.\nWe have the equation of the line, so let us draw it To do this we will use the abline() function. The parts of the function asks to specify the a= and b= so the full function should read abline(a=intercept,b=slope). We will throw in col= in order to color the line red. There are plenty of graphical options built into R, we will not go too in depth at the moment. `\nBefore inserting the function, we will need to plot our data first. When dealing with so-called ‘real’ data, your dependent variable should be the y and the independent should be the x.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Home",
      "Correlation"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DataSkills1",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "Lab-9.html",
    "href": "Lab-9.html",
    "title": "DataSkills1",
    "section": "",
    "text": "Before we dive into a new test, let us take a second to look back at the tests we have already covered and remember what those tests allowed us to do, and what the data for those tests looked like:\nZ-Test\n\nWhat does it do - The Z-test allows us to see if the scores from one population differ from another.\nWhat does our data look like - In order perform a Z-test, we need to have large enough sample to work with (N&gt;30) and we need to know \\(\\mu\\) and \\(\\sigma\\).\n\nT-Test\n\nWhat does it do - The T-test allows us to compare a sample to :\n\n\\(\\mu\\) when it is given, and when \\(\\sigma\\) is not.\nanother sample with paired values.\nanother sample with uncorrelated values\n\nWhat does our data look like - In order to perform a T-test, we need to have a sample that we are comparing to either, \\(\\mu\\), paired values, or a sample of (hopefully) equal length.\n\nWhy is ANOVA different?\nHere is what t-test for independent samples might look like:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nYou will notice that there are two columns, one for a condition of control and one for a condition of experimental.\nWe we have yet to discuss what this experiment actually is trying to answer, but, we can tell from looking at the data that whatever experimental is—it’s mean is higher than control and may be a significant difference.\nHere is what an ANOVA might look like:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nAs you can see, we still have two columns, but the main difference is that what used to be a condition two separate samples has become one single sample, separated by the various conditions.\nHerein lies the main difference between t-tests and ANOVAs: the amount of conditions (levels) that can be compared.\nt-tests can only compare two levels, while ANOVAs can compare more than two levels.\nThere are several notes to make when dealing with data in the format of an ANOVA.\nIt becomes essential that you understand the differences between an independent variable and a dependent variable.\nWhen you are dealing with 3 or more conditions, you need to convert them into factors if they are not already.\nfactors are a type of data that tell R which subjects are in which condition.\nYou can check if a vector is a factor by running the is.factor() function.\nWe we will go through some examples to see what it looks like when R recognizes a vector as a factor and when it does not.\nThe following example shows a vector of conditions. However, R does not know that these are conditions until we tell it that they are factors. If we are unsure if R knows if a vector is a factor, we can test it using is.factor :\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nNow that we know that R does not consider this vector to be a factor, we can manually tell R to make it a factor.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nNow R, will recognize example as a factor.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Home",
      "Analysis Of Variance (ANOVA)"
    ]
  },
  {
    "objectID": "Lab-9.html#analysis-of-variance-anova",
    "href": "Lab-9.html#analysis-of-variance-anova",
    "title": "DataSkills1",
    "section": "",
    "text": "Before we dive into a new test, let us take a second to look back at the tests we have already covered and remember what those tests allowed us to do, and what the data for those tests looked like:\nZ-Test\n\nWhat does it do - The Z-test allows us to see if the scores from one population differ from another.\nWhat does our data look like - In order perform a Z-test, we need to have large enough sample to work with (N&gt;30) and we need to know \\(\\mu\\) and \\(\\sigma\\).\n\nT-Test\n\nWhat does it do - The T-test allows us to compare a sample to :\n\n\\(\\mu\\) when it is given, and when \\(\\sigma\\) is not.\nanother sample with paired values.\nanother sample with uncorrelated values\n\nWhat does our data look like - In order to perform a T-test, we need to have a sample that we are comparing to either, \\(\\mu\\), paired values, or a sample of (hopefully) equal length.\n\nWhy is ANOVA different?\nHere is what t-test for independent samples might look like:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nYou will notice that there are two columns, one for a condition of control and one for a condition of experimental.\nWe we have yet to discuss what this experiment actually is trying to answer, but, we can tell from looking at the data that whatever experimental is—it’s mean is higher than control and may be a significant difference.\nHere is what an ANOVA might look like:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nAs you can see, we still have two columns, but the main difference is that what used to be a condition two separate samples has become one single sample, separated by the various conditions.\nHerein lies the main difference between t-tests and ANOVAs: the amount of conditions (levels) that can be compared.\nt-tests can only compare two levels, while ANOVAs can compare more than two levels.\nThere are several notes to make when dealing with data in the format of an ANOVA.\nIt becomes essential that you understand the differences between an independent variable and a dependent variable.\nWhen you are dealing with 3 or more conditions, you need to convert them into factors if they are not already.\nfactors are a type of data that tell R which subjects are in which condition.\nYou can check if a vector is a factor by running the is.factor() function.\nWe we will go through some examples to see what it looks like when R recognizes a vector as a factor and when it does not.\nThe following example shows a vector of conditions. However, R does not know that these are conditions until we tell it that they are factors. If we are unsure if R knows if a vector is a factor, we can test it using is.factor :\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nNow that we know that R does not consider this vector to be a factor, we can manually tell R to make it a factor.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nNow R, will recognize example as a factor.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Home",
      "Analysis Of Variance (ANOVA)"
    ]
  },
  {
    "objectID": "Lab-8.html",
    "href": "Lab-8.html",
    "title": "T-Test for paired Samples",
    "section": "",
    "text": "The t-test for paired samples may also be referred to as the t-test for correlated groups. In both cases, the subjects are measured twice. This can be actualized in a pre-treatment, post-treatment design where participants are measured on some aspect, given a treatment, and then measured again. The \\(H_0\\) for these t-tests are that the mean difference is 0. The \\(H_1\\) then becomes, that the difference is greater than 0 or less than 0.\nWhen we performed a sign test, we needed to supply R with the difference vector. When we do a paired t-test, we can provide both vectors and R will do the rest for us!\n\n\n\nFirst, create a distribution we can use for reproducibility using set.seed().\nExtract and compute the important information from the example you are given.\nCreate both of your vectors first, then combine them into a data frame. It is entirely possible to do all of this in one line, but syntax errors can run rampant when you have multiple arguments being passed at the same time!\nRecall that the arguments for t.test() when you are using a single sample will not work when you are working with paired samples.\nThe arguments are as follows:\ny1,y2 where y1 and y2 are both numeric vectors of the same length.\npaired = TRUE``\" This tells R that we are performing a paired t-test.\nvar.equal = TRUE This tells R that you are assuming the variances of both vectors are the same, by doing this you compute a certain kind of test. More on this later in the semester.\nMaking the full function look like this: t.test(y1, y2, paired = TRUE, var.equal = TRUE).\n\nWith this in mind, compute the t.test for the following example:\n\nA researcher is interested in whether students will perform better when they are allowed to use a computer to take notes compared to when they are only allowed to use pen and paper. He has 15 students take notes with pen and paper and then tests them. He then has them take notes with a computer and then tests them. Are the pen and paper test scores worse than the computer test scores? Compute the appropriate test for this design at an \\(\\alpha\\) level of .05.\n\nUse a seed of 3400 to create two samples of 15 students. Our prediction is that the students who use pen and paper to take notes will perform worse on the test compared to the students who use a computer to take notes. Choose means that will be appropriate for our prediction to be supported (without making the differences too…different!)\nCalculate the t value for the experiment and report whether or not there is a significance, and if so, what that significance means.\nRemember that when reporting to follow the proper format: \\[t(df) = t_{obt}, p =\\]\nAfter you have your answers, tell me your \\[t_{obt}\\] and we will create a vector to show the different values we get.\n\n\nRemember that the t-test for paired samples is also called the t-test for correlated groups. In this sense, they are related. The t-test for independent samples are for unrelated samples.\nWe have looked at differences between a calculated sample, and the population mean. We have also looked at differences between two samples in which the participants are the same in order to see if there is a difference less than or greater than zero.\nUsing an independent t-test will allow us to see if there are differences among groups.\n\nDo women interpret emotions better than men?\nDo religious individuals give more to charity than their non-religious counterparts?\nDo people rate violent actors as more angering than racist actors?\n\nAs you can see, it is quite easy to populate this list with more and more hypotheses.\nConsider the following example:\n\nGaby has the prettiest garden in all of Long Island. She gets the mots compliments and most pictures taken in her garden. Meanwhile, Kim has just an OK garden; it garners some attention for visitors and gets a few compliments here and there. Gaby would like to see if her garden is quantitatively different from Kim’s garden. An independent researcher, David, has visitor services hand a form to all of the patrons that come to the gardens on a particular day. He divides the garden walkways so that some people will only pass by her garden, and some people will only pass Kim’s garden. Patrons fill out on the form a rating from 1-5 ranging from attributes such as cleanliness, presentability, attractiveness, and awe-inspiring. These scores are then averaged into a single number. David aims to compare these ratings and see if Gaby’s garden is indeed ‘better’. He uses an \\(\\alpha\\) of .05. What can he conclude?\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nWe have used scatterplots to show relationships, and we have used barplot to visualize differences. When it comes to paired samples, it is best to use a boxplot to represent the differences between paired samples. A boxplot shows the median for a sample.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Home",
      "T-Test for paired Samples"
    ]
  },
  {
    "objectID": "Lab-8.html#t-test-example",
    "href": "Lab-8.html#t-test-example",
    "title": "T-Test for paired Samples",
    "section": "",
    "text": "First, create a distribution we can use for reproducibility using set.seed().\nExtract and compute the important information from the example you are given.\nCreate both of your vectors first, then combine them into a data frame. It is entirely possible to do all of this in one line, but syntax errors can run rampant when you have multiple arguments being passed at the same time!\nRecall that the arguments for t.test() when you are using a single sample will not work when you are working with paired samples.\nThe arguments are as follows:\ny1,y2 where y1 and y2 are both numeric vectors of the same length.\npaired = TRUE``\" This tells R that we are performing a paired t-test.\nvar.equal = TRUE This tells R that you are assuming the variances of both vectors are the same, by doing this you compute a certain kind of test. More on this later in the semester.\nMaking the full function look like this: t.test(y1, y2, paired = TRUE, var.equal = TRUE).\n\nWith this in mind, compute the t.test for the following example:\n\nA researcher is interested in whether students will perform better when they are allowed to use a computer to take notes compared to when they are only allowed to use pen and paper. He has 15 students take notes with pen and paper and then tests them. He then has them take notes with a computer and then tests them. Are the pen and paper test scores worse than the computer test scores? Compute the appropriate test for this design at an \\(\\alpha\\) level of .05.\n\nUse a seed of 3400 to create two samples of 15 students. Our prediction is that the students who use pen and paper to take notes will perform worse on the test compared to the students who use a computer to take notes. Choose means that will be appropriate for our prediction to be supported (without making the differences too…different!)\nCalculate the t value for the experiment and report whether or not there is a significance, and if so, what that significance means.\nRemember that when reporting to follow the proper format: \\[t(df) = t_{obt}, p =\\]\nAfter you have your answers, tell me your \\[t_{obt}\\] and we will create a vector to show the different values we get.\n\n\nRemember that the t-test for paired samples is also called the t-test for correlated groups. In this sense, they are related. The t-test for independent samples are for unrelated samples.\nWe have looked at differences between a calculated sample, and the population mean. We have also looked at differences between two samples in which the participants are the same in order to see if there is a difference less than or greater than zero.\nUsing an independent t-test will allow us to see if there are differences among groups.\n\nDo women interpret emotions better than men?\nDo religious individuals give more to charity than their non-religious counterparts?\nDo people rate violent actors as more angering than racist actors?\n\nAs you can see, it is quite easy to populate this list with more and more hypotheses.\nConsider the following example:\n\nGaby has the prettiest garden in all of Long Island. She gets the mots compliments and most pictures taken in her garden. Meanwhile, Kim has just an OK garden; it garners some attention for visitors and gets a few compliments here and there. Gaby would like to see if her garden is quantitatively different from Kim’s garden. An independent researcher, David, has visitor services hand a form to all of the patrons that come to the gardens on a particular day. He divides the garden walkways so that some people will only pass by her garden, and some people will only pass Kim’s garden. Patrons fill out on the form a rating from 1-5 ranging from attributes such as cleanliness, presentability, attractiveness, and awe-inspiring. These scores are then averaged into a single number. David aims to compare these ratings and see if Gaby’s garden is indeed ‘better’. He uses an \\(\\alpha\\) of .05. What can he conclude?\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nWe have used scatterplots to show relationships, and we have used barplot to visualize differences. When it comes to paired samples, it is best to use a boxplot to represent the differences between paired samples. A boxplot shows the median for a sample.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Home",
      "T-Test for paired Samples"
    ]
  },
  {
    "objectID": "Final-Review.html",
    "href": "Final-Review.html",
    "title": "DataSkills1",
    "section": "",
    "text": "We made it!\n\nI am quite proud of all of you for making it to this point. This was never an easy class, and it should not be. This class is designed to show you the basic concepts that underlie all of psychological analyses. Whether you go on to be clinical psychologists or in an entirely unrelated field, I hope that you will take away an understanding, and an appreciation for the science that floods the news daily. Being able to understand what all those numbers mean, will make you a better consumer of scientific knowledge.\n\n\n\n\n\nHere are some important functions and arguments to know:\nplot() - This is the function to graphically visualize your data. Within this function can be several arguments.\n\nx,y:The independent and dependent variable you are interested in\nmain =,xlab =, ylab =, sub =: Title, x-axis lable, y-axis label, and caption.\nxlim =,ylim =: These set parameters for the graph that will be drawn.\ncol = : Designates a desired color for the lines, and points that will be drawn.\npch =: Point character, assigns shape for points drawn.\npoints(): Plot additional points on an existing graph with pre-defined graphical parameters\n\n-cor() - This function will return the correlation, or r, of an entire dataframe, or of specified variables.\n-hist() - This function will create a histogram of a given variable, displaying its frequencies.\n\nbreaks = - This argument allows you to specify a bin width of your choice.\nlm() - This function allows you to create a linear model from which you can predict a variable, from another.\n\nthe ~ is used to delinate between the predicting variable and the predictor variable.\n\nFor example: lm(x~y) is different than lm(y~x).\n\nWhen using lm(), it is common to name the model something that makes sense + .mod..\n\n\n-summary() - This can be used on entire datasets to return the minimum, maximum, and median values.\n\nThis can also be used to expand a linear model to give you values such as the coefficient of correlation, slope and intercept.\n\n\n\n\nWhen using R-Studio, it is important that the math you do in the console follows the same rules as the math you would do on a calculator or a piece of paper.\nFor example:\nI have a dataset with a mean of 10, and a standard deviation of 7. What is the probability of having a score of 18?\nWe know the formula for this is the Z-Score formula: \\[z = \\frac{x - M}{\\sigma}\\] Depending on how you enter this data into R, you will get two different answers:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n() are very important to R, and your answers will either be incorrect or will not be ouput corectly if the () are misplaced/misused. Depending on how difficult you want to make your calculations, keeping track of your () placement is very important.\nThe below equation will not render the correct answer:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nNot too bad, we were only off by one hundred and fourteen thousand six hundred nintey-four.\n\n\n() matter, quite a lot. Additionally, here are the math operators you can use:\n+\n-\n*\n/\n^\nsqrt()\nbarplot - This is the overall function for creating a bar graph. It has several functions that go along with it.\ncol - This is the same idea from the color argument used in a scatter plot, however, with bar plots you need to add a concatenation if you are looking to plot more than one bar (which you should!).\ncol=c(\"white\",\"red\",\"blue\")\nnames.arg - This is similar to xlab,however, we are usually going to be referring to each bar by a different name so you will need to add a concatenation.\nnames.arg=c(\"Experimental\",\"Control\")\nData Generation\nset.seed() - This function specifies a ‘seed’ of your choice. By choosing a ‘seed’ you are ensuring the ability of the data you produce to be replicable either for the use of a problem set, or for troubleshooting.\nsample - This function allows you to create a sample from an existing vector. It has two arguments.\nx - The vector that you will be sampling from. It is important that whatever you decide to sample from x cannot be larger than the length of x.\nn - This specifies how many items you want to sample from x.\nSampling Example\nsample(x, 10)\nrnorm - This function returns whatever size you specify as a vector from the normal distribution.\nN - This is the size of the vector that you would like.\nmean - This is what you would like the mean of the data returned to be.\nsd - This is what you would like the standard deviation of the data returned to be.\nExample of rnorm rnorm(100, 120, 10)\nlibrary() - This function loads a package outside of the ones native to R. So far, the only package we will be using is BSDA.\nBSDA\nz.test() - This is the function you will use to perform a z test. It contains several arguments.\nx - This will be your vector that continues the data you will be comparing to \\(\\mu\\) and \\(\\sigma\\).\nsigma.x - This will be the population standard deviation, \\(\\sigma\\), which will usually be given to you in a question.\nmu - This will be the population mean, \\(\\mu\\), which will usually be given to you in a question.\nalternative - This argument specifies the directionality of the hypothesis you wish to test.\ntwo.sided - This argument specifies that you wish to run a 2-tailed test.\nlesser - This argument specified that you wish to run a 1-tailed test indicating that your sample is less than the population mean, \\(\\mu\\).\ngreater - This argument specified that you wish to run a 1-tailed test indicating that your sample is greater than the population mean, \\(\\mu\\).\nHere is what a full z.test function could look like:\nz.test(x, mu = 12, sigma.x = 3.12, alternative =\"two.sided\")\nSIGN.test() - This is the function you will use to perform a sign test. It contains several arguments.\nx - This will be your vector that continues the data that is the difference between the first group and second group.\nmd - This will rarely be given, but implied. The sign test will test against the \\(H_0\\), which states that no difference exists, so 0 should be the default value.\nalternative - This argument specifies the directionality of the hypothesis you wish to test.\ntwo.sided - This argument specifies that you wish to run a 2-tailed test.\nlesser - This argument specified that you wish to run a 1-tailed test indicating that your sample is less than the population mean, \\(\\mu\\).\ngreater - This argument specified that you wish to run a 1-tailed test indicating that your sample is greater than the population mean, \\(\\mu\\).\nHere is what a full sign test function could look like:\nSIGN.test(x, md = 0, alternative = \"two.sided\")\nT-Test: One-Sample, Paired, Independent\nt.test - This function contains several arguments, the results, as well as the type of test that is run will be determined on which you specify.\nx - This is a vector that you be comparing against the population mean, \\(\\mu\\).\ny1, y2 - These arguments specify two distinct vectors of the same length to be compared.\nmu - This will be the population mean, \\(\\mu\\), which will usually be given to you in a question.\nalternative - This argument specifies the directionality of the hypothesis you wish to test.\ntwo.sided - This argument specifies that you wish to run a 2-tailed test.\nlesser - This argument specified that you wish to run a 1-tailed test indicating that your sample is less than the population mean, \\(\\mu\\).\ngreater - This argument specified that you wish to run a 1-tailed test indicating that your sample is greater than the population mean, \\(\\mu\\).\nvar.equal = TRUE - This argument specifies that the variances are assumed to be equal.\npaired = TRUE - If specified, this will result in R assuming the sample(s) are to be paired.\nDetermining which Test will be run:\nSingle Sample T-Test\nt.test(x, mu = 23, alternative =\"lesser\")\nPaired Sample T-Test\nt.test(y1, y2, paired = TRUE, var.equal= TRUE, alternative = \"greater\")\nIndependent T-Test\nt.test(y1, y2, var.equal= TRUE, alternative = \"two.sided\")\n\n\n\n\n\nWe have learned three different kinds of ANOVA in this class.\n\n\naov(DV~IV)\n\nDV is what is being measured, usually a score, rating, measurement, etc.\nIV is what is being manipulated, in order for R to calculate anything, this must be a factor.\n\nfactor(variable) - This will produce the variable as a factor.\nThis produces One F\n\n\n\naov(DV~IV1*IV2)\n\nDV is what is being measured, usually a score, rating, measurement, etc.\nIV1 is what is being manipulated: Control, Treatment, Treatment 2, etc.\nIV2 is also what is being manipulted throughout the IV1.\n\nControl-High, Control-Medium, Control-Low\n\n\nThis produces Three F’s\n\n\n\naov(DV~IV+Error(Subject))\n\nDV is what is being measured, usually a score, rating, measurement, etc.\nIV1 is what is being manipulated: Control, Treatment, Treatment 2, etc.\nSubject is the ID of the participant taking the experiment, they factor into your analysis because their data is in each level of the independent variable. Must be a factor.\n\nThis produces One F.\n\n\n\n\n\n\nwilcox.test(y~A)\nwhere y is numeric\nA is A binary factor\n\n\n\nwilcox.test(y,x) #\ny is numeric x is numeric\n\n\n\nwilcox.test(y1,y2,paired=TRUE) # where y1 and y2 are numeric\n\n\n\nkruskal.test(y~A) # where y1 is numeric and A is a factor\n\n\n\nfriedman.test(y~A|B)\ny is data values\nA is a grouping factor\nB is a blocking factor",
    "crumbs": [
      "Home",
      "Final Review Sheet"
    ]
  },
  {
    "objectID": "Final-Review.html#final-review-sheet",
    "href": "Final-Review.html#final-review-sheet",
    "title": "DataSkills1",
    "section": "",
    "text": "We made it!\n\nI am quite proud of all of you for making it to this point. This was never an easy class, and it should not be. This class is designed to show you the basic concepts that underlie all of psychological analyses. Whether you go on to be clinical psychologists or in an entirely unrelated field, I hope that you will take away an understanding, and an appreciation for the science that floods the news daily. Being able to understand what all those numbers mean, will make you a better consumer of scientific knowledge.\n\n\n\n\n\nHere are some important functions and arguments to know:\nplot() - This is the function to graphically visualize your data. Within this function can be several arguments.\n\nx,y:The independent and dependent variable you are interested in\nmain =,xlab =, ylab =, sub =: Title, x-axis lable, y-axis label, and caption.\nxlim =,ylim =: These set parameters for the graph that will be drawn.\ncol = : Designates a desired color for the lines, and points that will be drawn.\npch =: Point character, assigns shape for points drawn.\npoints(): Plot additional points on an existing graph with pre-defined graphical parameters\n\n-cor() - This function will return the correlation, or r, of an entire dataframe, or of specified variables.\n-hist() - This function will create a histogram of a given variable, displaying its frequencies.\n\nbreaks = - This argument allows you to specify a bin width of your choice.\nlm() - This function allows you to create a linear model from which you can predict a variable, from another.\n\nthe ~ is used to delinate between the predicting variable and the predictor variable.\n\nFor example: lm(x~y) is different than lm(y~x).\n\nWhen using lm(), it is common to name the model something that makes sense + .mod..\n\n\n-summary() - This can be used on entire datasets to return the minimum, maximum, and median values.\n\nThis can also be used to expand a linear model to give you values such as the coefficient of correlation, slope and intercept.\n\n\n\n\nWhen using R-Studio, it is important that the math you do in the console follows the same rules as the math you would do on a calculator or a piece of paper.\nFor example:\nI have a dataset with a mean of 10, and a standard deviation of 7. What is the probability of having a score of 18?\nWe know the formula for this is the Z-Score formula: \\[z = \\frac{x - M}{\\sigma}\\] Depending on how you enter this data into R, you will get two different answers:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n() are very important to R, and your answers will either be incorrect or will not be ouput corectly if the () are misplaced/misused. Depending on how difficult you want to make your calculations, keeping track of your () placement is very important.\nThe below equation will not render the correct answer:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nNot too bad, we were only off by one hundred and fourteen thousand six hundred nintey-four.\n\n\n() matter, quite a lot. Additionally, here are the math operators you can use:\n+\n-\n*\n/\n^\nsqrt()\nbarplot - This is the overall function for creating a bar graph. It has several functions that go along with it.\ncol - This is the same idea from the color argument used in a scatter plot, however, with bar plots you need to add a concatenation if you are looking to plot more than one bar (which you should!).\ncol=c(\"white\",\"red\",\"blue\")\nnames.arg - This is similar to xlab,however, we are usually going to be referring to each bar by a different name so you will need to add a concatenation.\nnames.arg=c(\"Experimental\",\"Control\")\nData Generation\nset.seed() - This function specifies a ‘seed’ of your choice. By choosing a ‘seed’ you are ensuring the ability of the data you produce to be replicable either for the use of a problem set, or for troubleshooting.\nsample - This function allows you to create a sample from an existing vector. It has two arguments.\nx - The vector that you will be sampling from. It is important that whatever you decide to sample from x cannot be larger than the length of x.\nn - This specifies how many items you want to sample from x.\nSampling Example\nsample(x, 10)\nrnorm - This function returns whatever size you specify as a vector from the normal distribution.\nN - This is the size of the vector that you would like.\nmean - This is what you would like the mean of the data returned to be.\nsd - This is what you would like the standard deviation of the data returned to be.\nExample of rnorm rnorm(100, 120, 10)\nlibrary() - This function loads a package outside of the ones native to R. So far, the only package we will be using is BSDA.\nBSDA\nz.test() - This is the function you will use to perform a z test. It contains several arguments.\nx - This will be your vector that continues the data you will be comparing to \\(\\mu\\) and \\(\\sigma\\).\nsigma.x - This will be the population standard deviation, \\(\\sigma\\), which will usually be given to you in a question.\nmu - This will be the population mean, \\(\\mu\\), which will usually be given to you in a question.\nalternative - This argument specifies the directionality of the hypothesis you wish to test.\ntwo.sided - This argument specifies that you wish to run a 2-tailed test.\nlesser - This argument specified that you wish to run a 1-tailed test indicating that your sample is less than the population mean, \\(\\mu\\).\ngreater - This argument specified that you wish to run a 1-tailed test indicating that your sample is greater than the population mean, \\(\\mu\\).\nHere is what a full z.test function could look like:\nz.test(x, mu = 12, sigma.x = 3.12, alternative =\"two.sided\")\nSIGN.test() - This is the function you will use to perform a sign test. It contains several arguments.\nx - This will be your vector that continues the data that is the difference between the first group and second group.\nmd - This will rarely be given, but implied. The sign test will test against the \\(H_0\\), which states that no difference exists, so 0 should be the default value.\nalternative - This argument specifies the directionality of the hypothesis you wish to test.\ntwo.sided - This argument specifies that you wish to run a 2-tailed test.\nlesser - This argument specified that you wish to run a 1-tailed test indicating that your sample is less than the population mean, \\(\\mu\\).\ngreater - This argument specified that you wish to run a 1-tailed test indicating that your sample is greater than the population mean, \\(\\mu\\).\nHere is what a full sign test function could look like:\nSIGN.test(x, md = 0, alternative = \"two.sided\")\nT-Test: One-Sample, Paired, Independent\nt.test - This function contains several arguments, the results, as well as the type of test that is run will be determined on which you specify.\nx - This is a vector that you be comparing against the population mean, \\(\\mu\\).\ny1, y2 - These arguments specify two distinct vectors of the same length to be compared.\nmu - This will be the population mean, \\(\\mu\\), which will usually be given to you in a question.\nalternative - This argument specifies the directionality of the hypothesis you wish to test.\ntwo.sided - This argument specifies that you wish to run a 2-tailed test.\nlesser - This argument specified that you wish to run a 1-tailed test indicating that your sample is less than the population mean, \\(\\mu\\).\ngreater - This argument specified that you wish to run a 1-tailed test indicating that your sample is greater than the population mean, \\(\\mu\\).\nvar.equal = TRUE - This argument specifies that the variances are assumed to be equal.\npaired = TRUE - If specified, this will result in R assuming the sample(s) are to be paired.\nDetermining which Test will be run:\nSingle Sample T-Test\nt.test(x, mu = 23, alternative =\"lesser\")\nPaired Sample T-Test\nt.test(y1, y2, paired = TRUE, var.equal= TRUE, alternative = \"greater\")\nIndependent T-Test\nt.test(y1, y2, var.equal= TRUE, alternative = \"two.sided\")\n\n\n\n\n\nWe have learned three different kinds of ANOVA in this class.\n\n\naov(DV~IV)\n\nDV is what is being measured, usually a score, rating, measurement, etc.\nIV is what is being manipulated, in order for R to calculate anything, this must be a factor.\n\nfactor(variable) - This will produce the variable as a factor.\nThis produces One F\n\n\n\naov(DV~IV1*IV2)\n\nDV is what is being measured, usually a score, rating, measurement, etc.\nIV1 is what is being manipulated: Control, Treatment, Treatment 2, etc.\nIV2 is also what is being manipulted throughout the IV1.\n\nControl-High, Control-Medium, Control-Low\n\n\nThis produces Three F’s\n\n\n\naov(DV~IV+Error(Subject))\n\nDV is what is being measured, usually a score, rating, measurement, etc.\nIV1 is what is being manipulated: Control, Treatment, Treatment 2, etc.\nSubject is the ID of the participant taking the experiment, they factor into your analysis because their data is in each level of the independent variable. Must be a factor.\n\nThis produces One F.\n\n\n\n\n\n\nwilcox.test(y~A)\nwhere y is numeric\nA is A binary factor\n\n\n\nwilcox.test(y,x) #\ny is numeric x is numeric\n\n\n\nwilcox.test(y1,y2,paired=TRUE) # where y1 and y2 are numeric\n\n\n\nkruskal.test(y~A) # where y1 is numeric and A is a factor\n\n\n\nfriedman.test(y~A|B)\ny is data values\nA is a grouping factor\nB is a blocking factor",
    "crumbs": [
      "Home",
      "Final Review Sheet"
    ]
  },
  {
    "objectID": "Lab-10.html#one-way-anova-post-hoc-tests-and-review",
    "href": "Lab-10.html#one-way-anova-post-hoc-tests-and-review",
    "title": "DataSkills1",
    "section": "One-Way ANOVA: Post-Hoc Tests and Review",
    "text": "One-Way ANOVA: Post-Hoc Tests and Review\n\nReminders\nANOVA’s are used when the sample data consists of a dependent measure and more than two indpendent variables.\nThe sample data you have will have a dependent variable, and a grouping variable. This grouping variable needs to be made into a factor.\nIn order to do this, we need to use the factor() function.\nWhen R imports a csv file, there is an option to automatically import any string data as a factor.\nComputing the ANOVA in R is very similar to computing a linear regression:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nYou should notice that the two outputs share certain values. The F statistic is the same in both cases, as is the p-value. Additionally, the linear regression has the same two degrees of freedom: 3 and 36.\nWhen you are creating your ANOVA output, it is good practice to name the ANOVA as being a something.mod. This is helpful because you will be able to use this model name in other instances.\n\n\nPost-Hoc Tests\nPost-Hoc tests are useful because they allow us to see where the difference is in our data. If we have a One-Way ANOVA with five groups and we have a significant F value, we have no idea which groups are different.\nWe will be using two Post-Hoc tests: the TukeyHSD and the SNK.Test (Student-Newman-Keuls).\nWe will use the same data from before and try to find out where the difference is, or rather, which combinations of data are significantly different.\n\nTukey HSD\nThe TukeyHSD test stands for “Honestly-Significantly-Different”.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nFrom this output we can see that the p adj value corresponds to whether or not the specific comparison is significant.\nWe can see that there is a difference between the following groups:\nTreatment 2 and Control, Treatment 3 and Control, Treatment 2 and Treatment 1, Treatment 3 and Treatment 1, and Treatment 3 and Treatment 2.\nThere is not a significant difference between Treatment 1 and Control.\nIf you look at the columns labeled lwr and upr, these are the confidence intervals for this specific comparison. If the confidence intervals include 0, the comparison will not be significant.\nTo test this, if you notice, the comparison between Treatment and Control is the only comparison with a negative lower interval. The range of -2.32 -&gt; 11.36 includes 0 so we can determine it is not significant.\nThese results can also be visualized in the form of a plot.\n\n\nPlotting the Tukey Test\nIn order to plot the Tukey Test results you will need to pass the output of the Tukey Test into the plot() function.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nAs you can see from the graph, there are dashed lines to demarcate the line at 0. The only interval that crosses this range is the Treatment 1 and Control.\n\n\n\nStudent Newman Keuls\nThe Student Newman Keuls test is another post-hoc test that is used to make comparisons of differences between groups.\nThe Student Newman Keuls test is available through a package called agricolae.\nFirst, we will install the package using install.packages(\"PackageName\").\nSecond, we will load the package through the use of library(agricolae).\nThe arguments in the Student Newman Keuls test are as follows:\ny - This is where you will put your model, (this is why it is so important to store your models!) trt - This is the name of your grouping variable, it will need to appear in quotes. main - This is what the title of your output will be. alpha - This is where you will specify what alpha level you will be testing your comparisons against. console - This is the option that asks whether you want to see the output (you should always make it equal to TRUE)\nIn full:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThe output from the Newman Keuls test does not return p-values, however, the same ideas about the confidence intervals apply.\nYou will notice that Control and Treatment have ranges that include 0, (-6.01-10) and (-3.31-14.79) respectively.\nThe output also prints out a helpful tool: Means with the same letter are not significantly different.\nWe can see that Treatment 3 Treatment 2 are both different and Treatment 1 and Control are the same letter, indicating they are not significantly different.",
    "crumbs": [
      "Home",
      "Analysis Of Variance (ANOVA)"
    ]
  },
  {
    "objectID": "Lab-1.html",
    "href": "Lab-1.html",
    "title": "DataSkills1",
    "section": "",
    "text": "Introduction\nHello my dudes!\nWelcome to PSYC 3400: Statistical Methods in Behavioral Research. In this course, we will be using R-Studio in order to visualize and implement what you learn in lecture.\nIn other statistics classes, students will be learning the same exact materials using a program called SPSS. The main difference between SPSS and R-Studio is usability and price. SPSS is a proprietary product, which means it costs a lot of money. R-Studio on the other hand is freeware–which, as the name suggests is free.\n\n\nR-Studio\nR-Studio, or R as we will refer to it going forwards, is by no means difficult, however, it does require that you learn a new way to think. It can be downloaded here\n\n\nSimple Math Operations\nR can do simple math operations: (Addition, Subtraction, Division, Multiplication, Exponentiation)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThose same operations can be saved to a variable. Variables will hold that value when they are ‘called’ later.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nVariables\nWe can take a value and assign it to a variable. We can also take two variables and perform math operations on them. When dealing with real data, it is important to assign understandable variable names.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nIn this class, we will often use data sets. Single numbers are important, but most, if not all tests in Psychology make use of a dataset consisting of several numbers. In order to make a dataset in R we have two options.\n\nWe can upload a file to R and it will import accordingly\nWe can manually create the dataset, using a function called concatenation.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nCentral Tendency\n\nMeasures of Central Tendency\n\nMean - returns the average of the sample\nMedian = returns the middle number of the sample when put in ascending order\nRange = returns the lowest and highest data points in the set\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nWith the exception of the range, the mean and median tell us something about the data. They tell us that in this case, the mean for x is r mean(x) and the median is rmedian(x). When the median and the mean are the same it leads us to believe this is a fairly symmetrical dataset. In order to test this, we can plot a histogram. A histogram shows us frequency counts for every data point.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nBetween 0-1 there is exactly 1 point, between 2-4 there is exactly 1 point, etc. Let’s see what it looks like when there is some variation in the data.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nIn this course, the data that we are dealing with will have different properties assigned to it. Doing this will allow you to attach meaning into your interpretation while also showing you how to not only visualize, but also organize the data. We will be adding two new functions here: main = “” and xlab = ““. The main function tells R what to label the plot, and the xlab function tells R what to label the x-axis.\nConsider the following:\n\nA psychologist is interested in whether or not the students in his class are Android users or iPhone users. More specifically, he is interested in whether or not students who use Android phones spend more time on it during class than iPhone users. He observes his statistics class and obtains the following data.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nSo far we have learned that R allows us to do simple math problems, create datasets, extract some descriptions from the dataset and visualize how the data is distributed.\nThe next step is to look at data and see if there are any relationships present. Most of the data you collect or are given will have an established relationship. To start, let’s take a look at a dataset that is manufactured to have a somewhat perfect relationship.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nWe can clearly see that the distance between each point is the same. Without any idea of what x and y represent all we can say is that it appears that there seems to be a relationship or a pattern.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nRealistically, looking at this makes sense but are we to believe that working 4 hours yields a result of $2 pay? The data you look at should have context attached to it. Additionally, most data that you are working with will have more than 4 data points.\nSo let’s see what a dataset of 20 does to our visualization.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThe above data creation function is not important for you to know. But I want to make sure that anything I do, you can see so you understand where information is coming from.\nFrom this data set, we wouldn’t really be able to make any discernible, objective interpretation of this plot.\nIs there a relationship between hours of TV watched and hours slept? Maybe, but not in the data we collected! This is the important thing to note about this class, and most of science that you will see in your life. Just because you see a chart or a graph, does not mean that it is right or true. I am here to teach you how to use R-Studio to perform statistical calculations, but I am also here to be a proponent for scientific literacy.\n\n\nDataframes\nMost of the data you will be dealing with in this class will be from a set. The examples in the beginning of class focused mainly on simple operations in R. A “real” dataset may have several variables.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nIn this hypothetical, a researcher is interested in whether or not the number of absences a student has, has any effect on the grade that student receives on a test. In order to test this, we should probably make a plot of the different variables. We could simply just type out the variables, but it is better to “call” them using a $.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Home",
      "Introduction"
    ]
  },
  {
    "objectID": "Links.html",
    "href": "Links.html",
    "title": "Resources",
    "section": "",
    "text": "R and R-Studio\nR is a free open-source programming language that can be used for statistical analysis, data-simulation, graphing, and lots of other stuff. Another free program is R-studio, that provides a nice graphic interface for R. Download R first, then download R-studio. Both can run on PCs, Macs or Linux. Students will be learning R in the stats labs using the lab manual .\n\n\nAdditional R resources\n\nGoogle is great, Google your problem\nStackoverflow is great, google will often take you there because someone has already asked your question, and someone else has answered, usually many people have answered your question many ways.\nDanielle Navarro wrote a free Psych Stats textbook using R, it’s worth checking out (some of our textbook are based on Danielle’s)\nI am currently writing another stats textbook (incorporating some of the above). You can read it while it’s being made right here https://crumplab.github.io/statistics/, also check out the lab manual for more specific things about doing various stats in R (also in draft right now) https://crumplab.github.io/statisticsLab/\nDaniell Navarro recently made this website for introducing R, it’s great, check it out (also made using this R markdown process): http://compcogscisydney.org/psyr/\nCheck out my slightly older programming book that also introduces R https://crumplab.github.io/programmingforpsych/\nThis is the definitive guide for all things R Markdown (you will find this very useful as you get better at this skill): https://bookdown.org/yihui/rmarkdown/"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "Lab-5.html",
    "href": "Lab-5.html",
    "title": "DataSkills1",
    "section": "",
    "text": "Before we can talk about inferential statistics we have to understand probability.\nWe all know, that if I toss a quarter in the air. There are only two possible options. Either the coin lands on a head, or it lands on a tail.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nBy using the sample() function, we can tell R to randomly sample an event for us.\nWe ‘tossed’ a coin, and it landed on heads. What is the probability of this happening?\nProbability is written as:\n\\[P(A) = \\frac{1}{2} = .5000\\]\nIn other words, the number of possible outcomes favorable to A divided by the total number of possible outcomes.\nLet’s think about this in terms of playing cards:\nIn a standard card deck, there are 52 total cards:\n\nTwo Colors: Red and Black\nFour Suits: Clubs, Hearts, Spades, Diamonds\n2,3,4,5,6,7,8,9,10,J,Q,K,A\n\nWhat is the probability of picking a King of Hearts\n\\[P(King of Hearts) = \\frac{1}{52}= .0192\\]\nWhat is the probability of picking a 10 of Hearts and a Nine of Hearts with replacement?\n\\[P(10 of Hearts) - P(9 of Hearts) \\frac{1}{52}X \\frac{1}{52} = .01923X .01923 = .00037\\] What is the probability of picking a 10 of Hearts and a Nine of Hearts without replacement?\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\\[P(10 of Hearts) - P(9 of Hearts) \\frac{1}{52}X \\frac{1}{51} = .01923X .01961 = .00037\\]\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nIn order to do work with some datasets, we need to know what they are composed of. So far we have many worked with numbers. If we were to look at string data. Also know as, character data, we can use a new command called which(). Additionally we can also use a workaround using something new: ==. Without getting into the details, there is a difference between = and ==.\nThere are two different ways we can break-up our data.\nWe can use a command such as:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Home",
      "Probability"
    ]
  },
  {
    "objectID": "Lab-5.html#probability",
    "href": "Lab-5.html#probability",
    "title": "DataSkills1",
    "section": "",
    "text": "Before we can talk about inferential statistics we have to understand probability.\nWe all know, that if I toss a quarter in the air. There are only two possible options. Either the coin lands on a head, or it lands on a tail.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nBy using the sample() function, we can tell R to randomly sample an event for us.\nWe ‘tossed’ a coin, and it landed on heads. What is the probability of this happening?\nProbability is written as:\n\\[P(A) = \\frac{1}{2} = .5000\\]\nIn other words, the number of possible outcomes favorable to A divided by the total number of possible outcomes.\nLet’s think about this in terms of playing cards:\nIn a standard card deck, there are 52 total cards:\n\nTwo Colors: Red and Black\nFour Suits: Clubs, Hearts, Spades, Diamonds\n2,3,4,5,6,7,8,9,10,J,Q,K,A\n\nWhat is the probability of picking a King of Hearts\n\\[P(King of Hearts) = \\frac{1}{52}= .0192\\]\nWhat is the probability of picking a 10 of Hearts and a Nine of Hearts with replacement?\n\\[P(10 of Hearts) - P(9 of Hearts) \\frac{1}{52}X \\frac{1}{52} = .01923X .01923 = .00037\\] What is the probability of picking a 10 of Hearts and a Nine of Hearts without replacement?\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\\[P(10 of Hearts) - P(9 of Hearts) \\frac{1}{52}X \\frac{1}{51} = .01923X .01961 = .00037\\]\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nIn order to do work with some datasets, we need to know what they are composed of. So far we have many worked with numbers. If we were to look at string data. Also know as, character data, we can use a new command called which(). Additionally we can also use a workaround using something new: ==. Without getting into the details, there is a difference between = and ==.\nThere are two different ways we can break-up our data.\nWe can use a command such as:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Home",
      "Probability"
    ]
  },
  {
    "objectID": "Lab-5.html#proportioning-data",
    "href": "Lab-5.html#proportioning-data",
    "title": "DataSkills1",
    "section": "Proportioning Data",
    "text": "Proportioning Data\nThe below code will allow you to take a set of data and see what proportion is accounted for given a certain criteria.\nFor example: If I have a data set of 1’s and 0’s, how can I know how many I have of each. Additionally, how can I tell the proportion of each?\nTo do this we need to use the which()command as well as how much of the data is made up of 1’s and 0’s.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nWe can see here that the amount of 1’s is pretty close to the amount of 0’s. Now let us try with a more involved example.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nThe rnorm Function\nIn most, if not all of my slides, you have seen me use the function rnorm(). In class, I’ve used this as a way to generate large sets of data with one line of text. There are a few arguments that are necessary in order to take this function and use it for the purposes of sampling.\nrnorm() stands for “Random Normal”. Essentially, what rnorm() does it create a random set of numbers (specified by you) and generates data.\nHere are the arguments rnorm() accepts:\n\nn: Specifies the number of data points you want to create.\nmean: Specifies the mean you want your sample to have.\nsd: Specifies the standard deviation you want your sample to have.\n\nAlthough not essential, a nice function to use is round( digits = )\n\nThis function makes your data look a little bit neater, you will see that when we create a sample from rnorm() the numbers are a little messy.\n\nSo, let’s make a sample of 20 numbers with a mean of 12 and a standard deviation of 3.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nSee how the numbers came out a little unwieldy? Let’s fix that:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nNotice how the digits= command is preceded by a comma. This is because it is a part of the round() function but not a part of the rnorm() function.\nWe can specify the mean and the standard deviation of the dataset, but does introducing the variability of the standard deviation make it harder for the mean to be exactly what we asked for? Let’s see!\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nSampling\nWe can have our dataset of 100 points, but if we take a sample of that data, how representative will it be if the true mean?\nLet’s take a look:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nDo you see how it becomes difficult to tell a certain property of a random sample when you only have small sample to use?",
    "crumbs": [
      "Home",
      "Probability"
    ]
  },
  {
    "objectID": "Lab-6.html",
    "href": "Lab-6.html",
    "title": "DataSkills1",
    "section": "",
    "text": "The wonderful thing about R, is that once you know to use it, you can use libraries that process unlimited numbers of statistics. In order to do this, one needs to learn a few commands in order to access these online libraries and use them. With Exercise 06, we introduce the downloading of the BSDA package. Within this package comes the functions z.test and SIGN.test.\nFirst, install the package: install.packages(BSDA)\nAfter installing it on your computer, you can use at anytime you want by telling R to use the package. You do this by:library(BSDA)\n\n\nIn order to compute a Z-Test, you will need a dataset. This is a single column of numbers, or in R-Speak, a vector.\nThis will be compared against the known population mean \\(\\mu\\) (mu) and standard deviation \\(\\sigma\\) (sigma.x).\nThe z.test() accepts the following arguments:\nx - a numeric vector\nmu = - A single number representing the mean.\nsigma.x - A single number representing the population standard deviation for x.\nalternative = \"two.sided\",\"less\",\"greater\" - Specification of the alternative hypothesis.\nSo, in review, your use of the z.test() function should look like this:\nz.test(x=,mu=, sigma.x=, alternative = \"two.sided\")\n\n\nIn order to perform a Z-Test, you need to have a specified \\(\\sigma\\) and \\(\\mu\\).\nIn order to find the Standard Error of the mean we need to do the following computation.\n\\[\\sigma_\\bar{x} = \\frac{s}{\\sqrt{n}}\\] We also need to find the mean of the sample:\n\\[\\bar{x{}} = \\frac{\\Sigma X}{n}\\]\nThen we can plug that into the Z formula.\n\\[z = \\frac{\\bar{x}-\\mu}{\\sigma_x}\\]\nLet’s use this in an example.\n\nDave knows that from his experience working with undergraduate participants on tasks related to attention that the population mean is 71 and the standard deviation is 2.4. He measures the attention scores of 13 participants and finds the following:\n\n71,74,73,71,78,73,72,71,73,72,74,72,75\nFirst, we can find the SEM.\n\\[\\sigma_x = \\frac{2.4}{\\sqrt{13}} = .66\\]\nThen we will need to find the mean:\n\\[Xbar = \\frac{71+74+73+71+78+73+72+71+73+72+74+72+75}{13} = 73 \\]\nWe can then plug that into the Z formula:\n\\[Z_{obt} = \\frac{73-71}{.66} = 3.03\\] Then we can look in the Z-Table for the \\(Z_{crit}\\) of .05 is 1.64.\nBecause \\(Z_{obt} &gt; Z_{crit}\\), we can reject the null hypothesis that there is no difference.\nWe can write this as:\n\\(Z_{obt}(13) = +3.03 &lt; .05\\)\nNow we can see how R tackles the same problem.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThe output that is given by the z.test function gives us much more than we need for right now. Note that the Z value is slightly different, this is mainly due to how th computer parses the data. You will also see that this output gives an exact value for p. For right now, stick to indicating if your \\(Z_{obt}\\) is &gt; or &lt; \\(\\alpha{_.05}\\).\n\n\n\n\n\nFor the sign test, we will be determining whether or not a difference is due to chance. The sign test uses the number of pluses + and minuses - to determine the strength of an effect. We will be using the BSDA package again, specifically the SIGN.test() function.\nThe SIGN.test() function accepts the following argments:\nx - a vector of difference scores\nmd = - This is your cut-off point. Unless specified, a common cut-off point is 0. If there was no effect, there would be a difference of 0 between 1 treatment and and another.\nalternative = - Much like the z.test, this can be either two.sided, lesser or greater. You can think of the latter two as being equal to one tailed negative and one tailed positive.\nYour full SIGN.test()function should look something like this:\nSIGN.test(x = , md = , alternative = \" \")\n\n\nA researcher is interested to see whether his students respond perform better on tests when they listen to metal music playing while they study compared to when they study with classical music. He takes 10 students and measures their scores on an exam after they listened to metal music while studying. He then later collects their scores on their tests while they listened to classical music, he then measures the difference. Using an \\(\\alpha\\) level of .05, what can he conclude?\nTo visualize this, let us create this data.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nWe cannot do any analyses on character data right now, so let’s make sure to convert those values to numbers just so we can see.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nSo we have two minuses and 8 pluses. What is the probability associated with this outcome with a sample of 10? In other words, think of this as \\(p(8)\\) which necessarily includes \\(p(9)\\) and \\(p(10)\\).\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThe researcher can conclude that there appears to be no significant difference in test results from students who listen to metal music while studying compared to students who listened to classical music while studying.\nWe can see from the output that we are just shy of being significant. It will be good practice to be rather dichotomous, much like the sign test in saying you are either below your \\(\\alpha\\) level, or above it.\nNow, let’s go backwards a bit: When we calculated a z-test, we did it by “hand” and then by computer. Now let us perform the same sign test by “hand”.\nAll we need to know is that we ended up with 8 pluses (+) and two minuses (-).\nWe can look at the binomial table, in the column for .50 where n = 10.\nWe will need to add the probabilities of \\(p(8)\\),\\(p(9)\\), and \\(p(10)\\) to get our answer:\n\\[p(8)+p(9)+p(10) = .0439 + .0098 + .0010 + = .0547 \\]\n\n\n\n\nWe have learned about vectors and mainframes. We will now learn about matrices. A matrix is a set of numbers that do something.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nWhen creating a matrix, you can define your number of columns and number of rows through the use of\nnrow= and ncol=.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nOnce you have a matrix you can refer to a specific data point using [,]. The way this works is that anything inside of the left bracket ([) will refer to the row. Anything inside of the right bracket (]) will refer to the column.\nLet’s try it out.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nSo far in this class, we have looked at data sets, and performed analyses. The next step is to report these findings.\nAll of psychology uses APA style writing. Within this writing style there is a special style to report results.\nFrom this point forward, on your homework if you do any analyses and are asked to report your findings, you must use proper statistical formatting in order to get all of the points.\nThe Z-Test deals with significance, as does the Sign Test.\nIn most cases, you will be reporting as follows:\nYou will be reporting probabilities.\np = ns\nor\np = .004\n\nZ-Test: \\(Z_{obt}(n) = (+/-)Score &gt; &lt; = \\alpha\\)\nSign Test: \\(p = .four places\\)",
    "crumbs": [
      "Home",
      "Packages"
    ]
  },
  {
    "objectID": "Lab-6.html#packages",
    "href": "Lab-6.html#packages",
    "title": "DataSkills1",
    "section": "",
    "text": "The wonderful thing about R, is that once you know to use it, you can use libraries that process unlimited numbers of statistics. In order to do this, one needs to learn a few commands in order to access these online libraries and use them. With Exercise 06, we introduce the downloading of the BSDA package. Within this package comes the functions z.test and SIGN.test.\nFirst, install the package: install.packages(BSDA)\nAfter installing it on your computer, you can use at anytime you want by telling R to use the package. You do this by:library(BSDA)\n\n\nIn order to compute a Z-Test, you will need a dataset. This is a single column of numbers, or in R-Speak, a vector.\nThis will be compared against the known population mean \\(\\mu\\) (mu) and standard deviation \\(\\sigma\\) (sigma.x).\nThe z.test() accepts the following arguments:\nx - a numeric vector\nmu = - A single number representing the mean.\nsigma.x - A single number representing the population standard deviation for x.\nalternative = \"two.sided\",\"less\",\"greater\" - Specification of the alternative hypothesis.\nSo, in review, your use of the z.test() function should look like this:\nz.test(x=,mu=, sigma.x=, alternative = \"two.sided\")\n\n\nIn order to perform a Z-Test, you need to have a specified \\(\\sigma\\) and \\(\\mu\\).\nIn order to find the Standard Error of the mean we need to do the following computation.\n\\[\\sigma_\\bar{x} = \\frac{s}{\\sqrt{n}}\\] We also need to find the mean of the sample:\n\\[\\bar{x{}} = \\frac{\\Sigma X}{n}\\]\nThen we can plug that into the Z formula.\n\\[z = \\frac{\\bar{x}-\\mu}{\\sigma_x}\\]\nLet’s use this in an example.\n\nDave knows that from his experience working with undergraduate participants on tasks related to attention that the population mean is 71 and the standard deviation is 2.4. He measures the attention scores of 13 participants and finds the following:\n\n71,74,73,71,78,73,72,71,73,72,74,72,75\nFirst, we can find the SEM.\n\\[\\sigma_x = \\frac{2.4}{\\sqrt{13}} = .66\\]\nThen we will need to find the mean:\n\\[Xbar = \\frac{71+74+73+71+78+73+72+71+73+72+74+72+75}{13} = 73 \\]\nWe can then plug that into the Z formula:\n\\[Z_{obt} = \\frac{73-71}{.66} = 3.03\\] Then we can look in the Z-Table for the \\(Z_{crit}\\) of .05 is 1.64.\nBecause \\(Z_{obt} &gt; Z_{crit}\\), we can reject the null hypothesis that there is no difference.\nWe can write this as:\n\\(Z_{obt}(13) = +3.03 &lt; .05\\)\nNow we can see how R tackles the same problem.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThe output that is given by the z.test function gives us much more than we need for right now. Note that the Z value is slightly different, this is mainly due to how th computer parses the data. You will also see that this output gives an exact value for p. For right now, stick to indicating if your \\(Z_{obt}\\) is &gt; or &lt; \\(\\alpha{_.05}\\).\n\n\n\n\n\nFor the sign test, we will be determining whether or not a difference is due to chance. The sign test uses the number of pluses + and minuses - to determine the strength of an effect. We will be using the BSDA package again, specifically the SIGN.test() function.\nThe SIGN.test() function accepts the following argments:\nx - a vector of difference scores\nmd = - This is your cut-off point. Unless specified, a common cut-off point is 0. If there was no effect, there would be a difference of 0 between 1 treatment and and another.\nalternative = - Much like the z.test, this can be either two.sided, lesser or greater. You can think of the latter two as being equal to one tailed negative and one tailed positive.\nYour full SIGN.test()function should look something like this:\nSIGN.test(x = , md = , alternative = \" \")\n\n\nA researcher is interested to see whether his students respond perform better on tests when they listen to metal music playing while they study compared to when they study with classical music. He takes 10 students and measures their scores on an exam after they listened to metal music while studying. He then later collects their scores on their tests while they listened to classical music, he then measures the difference. Using an \\(\\alpha\\) level of .05, what can he conclude?\nTo visualize this, let us create this data.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nWe cannot do any analyses on character data right now, so let’s make sure to convert those values to numbers just so we can see.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nSo we have two minuses and 8 pluses. What is the probability associated with this outcome with a sample of 10? In other words, think of this as \\(p(8)\\) which necessarily includes \\(p(9)\\) and \\(p(10)\\).\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThe researcher can conclude that there appears to be no significant difference in test results from students who listen to metal music while studying compared to students who listened to classical music while studying.\nWe can see from the output that we are just shy of being significant. It will be good practice to be rather dichotomous, much like the sign test in saying you are either below your \\(\\alpha\\) level, or above it.\nNow, let’s go backwards a bit: When we calculated a z-test, we did it by “hand” and then by computer. Now let us perform the same sign test by “hand”.\nAll we need to know is that we ended up with 8 pluses (+) and two minuses (-).\nWe can look at the binomial table, in the column for .50 where n = 10.\nWe will need to add the probabilities of \\(p(8)\\),\\(p(9)\\), and \\(p(10)\\) to get our answer:\n\\[p(8)+p(9)+p(10) = .0439 + .0098 + .0010 + = .0547 \\]\n\n\n\n\nWe have learned about vectors and mainframes. We will now learn about matrices. A matrix is a set of numbers that do something.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nWhen creating a matrix, you can define your number of columns and number of rows through the use of\nnrow= and ncol=.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nOnce you have a matrix you can refer to a specific data point using [,]. The way this works is that anything inside of the left bracket ([) will refer to the row. Anything inside of the right bracket (]) will refer to the column.\nLet’s try it out.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nSo far in this class, we have looked at data sets, and performed analyses. The next step is to report these findings.\nAll of psychology uses APA style writing. Within this writing style there is a special style to report results.\nFrom this point forward, on your homework if you do any analyses and are asked to report your findings, you must use proper statistical formatting in order to get all of the points.\nThe Z-Test deals with significance, as does the Sign Test.\nIn most cases, you will be reporting as follows:\nYou will be reporting probabilities.\np = ns\nor\np = .004\n\nZ-Test: \\(Z_{obt}(n) = (+/-)Score &gt; &lt; = \\alpha\\)\nSign Test: \\(p = .four places\\)",
    "crumbs": [
      "Home",
      "Packages"
    ]
  },
  {
    "objectID": "Lab-4.html#graphical-additions",
    "href": "Lab-4.html#graphical-additions",
    "title": "DataSkills1",
    "section": "Graphical Additions",
    "text": "Graphical Additions\nWe have already seen the basics of using graphics to visualize our data with functons such as plot() and hist().Additionally, we have seen that we can do certain things to clean-up our visualizations such as providing titles and captions through the use of main=\"Title\", sub=\"Caption\" and respectively, adding axis lables with xlab=\"X\", ylab=\"Y\". `\nWe have also seen how to draw a line through the points that would best explain the relationship present if any, in the dat through the use of abline(a=,b=).\n\nset.seed(105)\nvar1=rnorm(10,30)\nvar2=rnorm(10,23)\nplot(var1,var2,main=\"Some Nice Title\",xlab = \"Variable 1\",ylab=\"Variable 2\", sub=\"r = .64 \" )\n\n\n\n\n\n\n\nvar.mod&lt;-lm(var2~var1)\nsummary(var.mod)\n\n\nCall:\nlm(formula = var2 ~ var1)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.22571 -0.00482  0.11789  0.26722  0.44729 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)   6.0602     7.0975   0.854   0.4180  \nvar1          0.5510     0.2368   2.327   0.0484 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5139 on 8 degrees of freedom\nMultiple R-squared:  0.4036,    Adjusted R-squared:  0.3291 \nF-statistic: 5.414 on 1 and 8 DF,  p-value: 0.0484\n\n\nWe can tell that this line is equal to: \\(Y= 6.060 + .551\\)\nIn our discussion on linear regressin we discussed how to add the line of best fit through the use of the abline() function.\n\nplot(var1,var2)\nabline(a=6.060,b=.551,col=\"red\")\n\n\n\n\n\n\n\n\nAdditionally, we can color the line through the use of col=\" \". R has quite the selection of colors available to you. The colors() function, you will see an output of 657 possible colors. Here are just a few:\n\ncl=colors()\nsample(cl,5)\n\n[1] \"navajowhite\"     \"cyan3\"           \"gray28\"          \"mediumslateblue\"\n[5] \"gray65\"         \n\n\nIf you can think of a color, there is a name for it in R (most likely!)\nNow that we have colors nailed down, we can mention point characters, or as they are called in R pch=. This function will allow you to change how a point looks. Here is an example:\n\nset.seed(71)\nx=rnorm(100,50)\ny=rnorm(100,25)\nplot(x,y,pch=2)\n\n\n\n\n\n\n\n\nHere is an image of some of the possible choices you will can use. \nIf I wanted to plot a graph with green, filled in squares, I would do this:\n\nset.seed(60)\nx=rnorm(15,100);y=rnorm(15,50)\nplot(x,y,col=\"green\",pch=15)\n\n\n\n\n\n\n\n\nOkay, so we can add colors and shapes to our graphs. So what? What if we wanted to display certain information in a certain way, or what if we wanted to separate our data in some distinguishing way?\nIf you are presented with a dataset with more than one independent variable, it can be difficult to discern any relationship when you have to graph it twice. Additionally we will calculate the linerar regression summaries of each independent vairables:\n\nset.seed(10)\n\nAttention_Experiment&lt;-data.frame(Age=round(rnorm(50,17,2),digits = 0),Minutes_Phone=round(rnorm(50,120,5),digits=2),Test_Score=round(rnorm(50,80,10),digits=2))\n\nplot(Attention_Experiment$Test_Score~Attention_Experiment$Age,xlab=\"Age\",ylab=\"Test Score\")\n\n\n\n\n\n\n\nplot(Attention_Experiment$Minutes_Phone~Attention_Experiment$Age,xlab=\"Age\",ylab=\"Hours TV Watched\")\n\n\n\n\n\n\n\nTest_Age.mod&lt;-lm(Attention_Experiment$Test_Score~Attention_Experiment$Age)\n\nPhone_Use.mod&lt;-lm(Attention_Experiment$Minutes_Phone~Attention_Experiment$Age)\n\nsummary(Test_Age.mod)\n\n\nCall:\nlm(formula = Attention_Experiment$Test_Score ~ Attention_Experiment$Age)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-20.509  -7.738   2.219   7.314  14.414 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)               78.4391    12.9521   6.056 2.06e-07 ***\nAttention_Experiment$Age   0.1105     0.7900   0.140    0.889    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.82 on 48 degrees of freedom\nMultiple R-squared:  0.0004075, Adjusted R-squared:  -0.02042 \nF-statistic: 0.01957 on 1 and 48 DF,  p-value: 0.8893\n\nsummary(Phone_Use.mod)\n\n\nCall:\nlm(formula = Attention_Experiment$Minutes_Phone ~ Attention_Experiment$Age)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.3595 -3.3896  0.4043  3.2590 10.7080 \n\nCoefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              120.59529    6.50609  18.536   &lt;2e-16 ***\nAttention_Experiment$Age  -0.01564    0.39685  -0.039    0.969    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.933 on 48 degrees of freedom\nMultiple R-squared:  3.235e-05, Adjusted R-squared:  -0.0208 \nF-statistic: 0.001553 on 1 and 48 DF,  p-value: 0.9687\n\n\nWe could take the correlation using cor() and see what the value of R-Squared was and keep looking back and forth, but there is a (somewhat) easier way!\nFor this we wil be introducing three new functions: points(), xlim=',ylim=,andhead()`.\nFirst: head() will show us a preview of our data, from here we can see where the values tend to lie, and get an idea of where our axes should be.\n\nhead(Attention_Experiment,10)\n\n   Age Minutes_Phone Test_Score\n1   17        118.00      72.38\n2   17        118.33      84.19\n3   14        126.84      69.60\n4   16        130.69      87.12\n5   18        122.53      73.67\n6   18        123.93      85.63\n7   15        115.49      86.61\n8   16        122.66      63.42\n9   14        116.77      90.28\n10  16        121.45      91.28\n\n\nAge has a minimum of 14 and a maximum of 18.Hours Watched has a minumum of 5.05 and maximum of 7.10. Test Score has a minumum of 58.81 and a maximum of 78.98.\nWe can use this information to create our new axis limits using xlim and ylim. Additionally. the points() function will be used in order to plot additional variables onto the existing plot. Finaly, we will use abline() to draw the line of best fit for each dataset.\n\nplot(Attention_Experiment$Test_Score~Attention_Experiment$Age,xlab=\"Age\",ylab=\"Test Score and Minutes on Phone\",xlim=c(10,20),ylim=c(20,150),col=\"red\",pch=15)\npoints(Attention_Experiment$Minutes_Phone~Attention_Experiment$Age,xlab=\"Age\",ylab=\"Hours TV Watched\",xlim=c(10,20),ylim=c(20,150),col=\"blue\",pch=15)\nlegend(\"bottomleft\",title=\"Legend\",c(\"Phone Usage\",\"Test Score\"),fill=c(\"red\",\"blue\"),cex = .8)\nabline(Test_Age.mod,col=\"blue\")\nabline(Phone_Use.mod,col=\"red\")\n\n\n\n\n\n\n\n\nThat was a lot to squeeze into two lines so let’s just go over it one last time.\n\nplot() Draw a graph of your points, it accepts the following inputs:\n\nx,y:The independent and dependent variable you are interested in\nmain =,xlab =, ylab =, sub =: Title, x-axis lable, y-axis label, and caption.\nxlim =,ylim =: These set parameters for the graph that will be drawn.\ncol = : Designates a desired color for the lines, and points that will be drawn.\npch =: Point character, assigns shape for points drawn.\n\npoints(): Plot additional points on an existing graph with pre-defined graphical parameters.",
    "crumbs": [
      "Home",
      "Additions to Linear Regression"
    ]
  },
  {
    "objectID": "webr.html",
    "href": "webr.html",
    "title": "webR in Quarto HTML Documents",
    "section": "",
    "text": "This is a webR-enabled code cell in a Quarto HTML document.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lab-2.html",
    "href": "Lab-2.html",
    "title": "DataSkills1",
    "section": "",
    "text": "Welcome back!\nHow did everyone find the exercises? Were they too difficult? Were they too easy? Were there any parts that you didn’t understand? Each week when an exercise is turned in I would like to take time in the beginning of lab to make sure that everyone is on the same page. Statistics, especially when using an unfamiliar program like R, can be quite difficult. If you fall behind it is essential that you let me know so I know what things to stress.\nFirst, let us do some review.\n\nWhat would I need to type into R to have it display a histogram of the dataset: 1,2,3,4,5,6,7,8,9,10?\nHow could I rename the x-axis on this plot so that it carried more information than it currently does?\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nUh-oh! I had just finished typing in a really long function and I accidentally forgot a comma. Is there any way for me to get everything I typed back without needing to retype it?\nGiven the following dataset, create a plot that shows the relationship between x and y, y and x, and z and y:\n\nx = {2,4,6,10,16,26,42} y = {1,3,5,7,9,11,13} z = {5,10,15,20,25,30,35}\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nBelow are two plots. Of the two, which one do you think shows a more apparent relationship or pattern?\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nAny questions?\n\nNew Material: Mean, Standard Deviation, Variance, Z-Score, Summation, and Stem and Leaf Plots\nYou will see the formula for the arithmetic mean in several different ways. Here are just a few.\n\\(\\mu = \\frac{\\sum x}{n}\\) or \\(M = \\frac{x_1 + x_2 + x_3...}{N}\\)\nIn other words, all numbers in a set should be added together and divided by the number of items in the set.\nStandard Deviation\n\\(\\sigma = \\sqrt\\frac{\\sum (x - \\mu)^2 }{n}\\)\nVariance\nVariance is simply \\((\\sigma ^2)\\)\nThis is the formula used to find a z score.\nZ is equal to the raw score \\(x\\) minus the mean \\(\\mu\\), divided by the standard deviation \\(\\sigma\\).\n\\(z =\\frac{x-\\mu}{\\sigma}\\)\nThere is no function in R to calculate a z-score, so instead we will have to use the built in functions for each part of the equation like such:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nHere are a few practice problems:\n\nFind the mean, standard deviation, and variance for the following dataset: datset1 = {10,63,51,24,87,42}\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nFind the z scores for the same dataset.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPerform the following summations on this dataset:\n\nx = (5,8,1,16,4,11)\n\n\\(\\sum X^2\\)\n\\(\\sum (X)^2\\)\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nSuppose that a psychologist wants to investigate the scores of his students in his statistics class. He may want to create a stem and leaf diagram in order to visualize the scores.\nHere is how he might do this for the following data:\n{85,90,88,95,90,91,85,94,83,86,90,90,88,94,90}\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nFrom this output we can infer a few things:\n\nSeveral students (9) scored somewhere in the 90’.\nNo students failed\nThere are two areas for scores in the 80’s and scores in the 90’s, this is because the first “leaf” represents values from 0-4 and the second “leaf” accounts for the 5-9.\n\nSimilar to histograms, ( hist(x, scale = )) we can manipulate how the stem and leaf plot is displayed using the following phrase: stem(x, scale =)\nWatch what happens when we use the different scale values.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThe first stem and leaf plot is the default you will get if you just type in stem(x). The second stem and leaf plot separates each leaf making the list twice as long. The third stem and leaf plot uses half the spacing as the first, so the scale is about half as long.",
    "crumbs": [
      "Home",
      "New Material: Mean, Standard Deviation, Variance, Z-Score, Summation, and Stem and Leaf Plots"
    ]
  }
]